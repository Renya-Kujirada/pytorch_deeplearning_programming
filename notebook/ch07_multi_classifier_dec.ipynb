{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch7QhC-aB8wI"
   },
   "source": [
    "# 7章　多値分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovFKq7VJB8wJ"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリの導入\n",
    "\n",
    "!pip install japanize_matplotlib | tail -n 1\n",
    "!pip install torchviz | tail -n 1\n",
    "!pip install torchinfo | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZuXbWMV0B8wK"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9HGKvQdjB8wK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# torch関連ライブラリのインポート\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xktdy7SfB8wK"
   },
   "outputs": [],
   "source": [
    "# デフォルトフォントサイズ変更\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# デフォルトグラフサイズ変更\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "# デフォルトで方眼表示ON\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# numpyの表示桁数設定\n",
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmcpTYteB8wL"
   },
   "source": [
    "## 7.8 データ準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXtUTacMB8wM"
   },
   "source": [
    "### データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DL7lXe4hB8wM",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元データ (150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# 学習用データ準備\n",
    "\n",
    "# ライブラリのインポート\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# データ読み込み\n",
    "iris = load_iris()\n",
    "\n",
    "# 入力データと正解データ取得\n",
    "x_org, y_org = iris.data, iris.target\n",
    "\n",
    "# 結果確認\n",
    "print('元データ', x_org.shape, y_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dOTzVWYB8wM"
   },
   "source": [
    "### データ絞り込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FgWVyVe_B8wM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元データ (150, 2) (150,)\n"
     ]
    }
   ],
   "source": [
    "# データ絞り込み\n",
    "\n",
    "# 入力データに関しては、sepal length(0)とpetal length(2)のみ抽出\n",
    "x_select = x_org[:,[0,2]]\n",
    "\n",
    "# 結果確認\n",
    "print('元データ', x_select.shape, y_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDu-VbBQB8wM"
   },
   "source": [
    "### 訓練データ・検証データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gHtoGNaiB8wN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2) (75, 2) (75,) (75,)\n"
     ]
    }
   ],
   "source": [
    "# 訓練データ、検証データに分割 (シャフルも同時に実施)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_select, y_org, train_size=75, test_size=75, \n",
    "    random_state=123)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hn8In74JB8wN"
   },
   "source": [
    "### 訓練データの散布図表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5duf5mMpB8wN"
   },
   "outputs": [],
   "source": [
    "# データを正解値ごとに分割\n",
    "\n",
    "x_t0 = x_train[y_train == 0]\n",
    "x_t1 = x_train[y_train == 1]\n",
    "x_t2 = x_train[y_train == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3 4.7]\n",
      " [7.  4.7]\n",
      " [5.  1.6]\n",
      " [6.4 5.6]\n",
      " [6.3 5. ]\n",
      " [5.  1.6]\n",
      " [4.9 1.4]\n",
      " [6.1 4. ]\n",
      " [6.5 4.6]\n",
      " [6.3 6. ]\n",
      " [5.8 1.2]\n",
      " [4.6 1.4]\n",
      " [5.5 3.8]\n",
      " [5.  1.6]\n",
      " [5.9 4.8]\n",
      " [6.9 5.4]\n",
      " [4.8 1.6]\n",
      " [6.7 5.8]\n",
      " [5.7 1.5]\n",
      " [5.7 1.7]\n",
      " [6.7 5. ]\n",
      " [4.6 1. ]\n",
      " [5.4 1.5]\n",
      " [6.6 4.6]\n",
      " [7.3 6.3]\n",
      " [6.6 4.4]\n",
      " [5.6 3.6]\n",
      " [5.6 3.9]\n",
      " [4.6 1.5]\n",
      " [5.  1.3]\n",
      " [6.8 4.8]\n",
      " [6.1 5.6]\n",
      " [4.9 1.5]\n",
      " [5.2 1.5]\n",
      " [5.6 4.2]\n",
      " [6.  4.5]\n",
      " [6.2 4.3]\n",
      " [7.1 5.9]\n",
      " [6.9 4.9]\n",
      " [5.8 4. ]\n",
      " [5.7 4.1]\n",
      " [7.6 6.6]\n",
      " [5.  1.5]\n",
      " [5.3 1.5]\n",
      " [5.9 4.2]\n",
      " [6.9 5.7]\n",
      " [6.4 5.5]\n",
      " [7.2 6. ]\n",
      " [6.5 5.2]\n",
      " [5.1 1.5]\n",
      " [5.4 4.5]\n",
      " [4.7 1.3]\n",
      " [5.8 4.1]\n",
      " [5.7 4.5]\n",
      " [5.  1.4]\n",
      " [6.2 4.5]\n",
      " [6.7 5.6]\n",
      " [6.  4.5]\n",
      " [6.7 5.7]\n",
      " [6.4 5.3]\n",
      " [5.2 1.5]\n",
      " [6.1 4.7]\n",
      " [4.6 1.4]\n",
      " [6.2 5.4]\n",
      " [5.7 5. ]\n",
      " [5.7 4.2]\n",
      " [4.9 3.3]\n",
      " [6.3 4.9]\n",
      " [4.9 4.5]\n",
      " [6.  5.1]\n",
      " [5.1 1.4]\n",
      " [5.1 3. ]\n",
      " [5.6 4.5]\n",
      " [6.2 4.8]\n",
      " [7.2 6.1]]\n",
      "---\n",
      "[False False  True False False  True  True False False False  True  True\n",
      " False  True False False  True False  True  True False  True  True False\n",
      " False False False False  True  True False False  True  True False False\n",
      " False False False False False False  True  True False False False False\n",
      " False  True False  True False False  True False False False False False\n",
      "  True False  True False False False False False False False  True False\n",
      " False False False]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(\"---\")\n",
    "print(y_train == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tYaWqq7IB8wN",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 散布図の表示\n",
    "\n",
    "plt.scatter(x_t0[:,0], x_t0[:,1], marker='x', c='k', s=50, label='0 (setosa)')\n",
    "plt.scatter(x_t1[:,0], x_t1[:,1], marker='o', c='b', s=50, label='1 (versicolour)')\n",
    "plt.scatter(x_t2[:,0], x_t2[:,1], marker='+', c='k', s=50, label='2 (virginica)')\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('petal_length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6jQZHH6B8wN"
   },
   "source": [
    "## 7.9 モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 2 2 0 0 1 1 2 0 0 1 0 1 2 0 2 0 0 1 0 0 1 2 1 1 1 0 0 1 2 0 0 1 1 1\n",
      " 2 1 1 1 2 0 0 1 2 2 2 2 0 1 0 1 1 0 1 2 1 2 2 0 1 0 2 2 1 1 2 2 1 0 1 1 2\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "x_train.shape[1]\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fUx0cencB8wO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_input: 2  n_output: 3\n"
     ]
    }
   ],
   "source": [
    "# 学習用パラメータ設定\n",
    "\n",
    "# 入力次元数\n",
    "n_input = x_train.shape[1]\n",
    "\n",
    "# 出力次元数\n",
    "# 分類先クラス数　今回は3になる\n",
    "n_output = len(list(set(y_train)))\n",
    "\n",
    "# 結果確認\n",
    "print(f'n_input: {n_input}  n_output: {n_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Q5UmhWa2B8wO"
   },
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "# 2入力3出力のロジスティック回帰モデル\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_output)\n",
    "                \n",
    "        # 初期値を全部1にする\n",
    "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
    "        self.l1.weight.data.fill_(1.0)\n",
    "        self.l1.bias.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        return x1\n",
    "    \n",
    "# インスタンスの生成\n",
    "net = Net(n_input, n_output)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVNOGdyTB8wO"
   },
   "source": [
    "### モデル確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qHvoNQRRB8wO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('l1.weight', Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], requires_grad=True))\n",
      "('l1.bias', Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "# モデル内のパラメータの確認\n",
    "# l1.weightが行列にl1.biasがベクトルになっている\n",
    "\n",
    "for parameter in net.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wiUZvDi_B8wP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (l1): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# モデルの概要表示\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nNobe3FvB8wP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/pytorch/pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Net                                      [3]                       --\n",
       "├─Linear: 1-1                            [3]                       9\n",
       "==========================================================================================\n",
       "Total params: 9\n",
       "Trainable params: 9\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのサマリー表示\n",
    "\n",
    "summary(net, (2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sBrtt-ZB8wP"
   },
   "source": [
    "### 最適化アルゴリズムと損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LmEw7VFWB8wP"
   },
   "outputs": [],
   "source": [
    "# 損失関数： 交差エントロピー関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 最適化関数: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "508vYI0zB8wP"
   },
   "source": [
    "## 7.10 勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKKMMHq2B8wP"
   },
   "source": [
    "### データのテンソル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cOg9_jE9B8wP"
   },
   "outputs": [],
   "source": [
    "# 入力変数x_trainと正解値 y_trainのテンソル変数化\n",
    "\n",
    "inputs = torch.tensor(x_train).float()\n",
    "labels = torch.tensor(y_train).long() # CrossEntoropyLossの第2引数は整数である必要があるため\n",
    "\n",
    "# 検証用変数のテンソル変数化\n",
    "\n",
    "inputs_test = torch.tensor(x_test).float()\n",
    "labels_test = torch.tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bo-FPvbQB8wQ"
   },
   "source": [
    "### 計算グラフの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Tv663B7hB8wQ"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"216pt\" height=\"391pt\"\n viewBox=\"0.00 0.00 216.00 391.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 387)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-387 212,-387 212,4 -4,4\"/>\n<!-- 139631144667632 -->\n<g id=\"node1\" class=\"node\">\n<title>139631144667632</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"130.5,-31 76.5,-31 76.5,0 130.5,0 130.5,-31\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 139631144408112 -->\n<g id=\"node2\" class=\"node\">\n<title>139631144408112</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-86 47,-86 47,-67 160,-67 160,-86\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">NllLossBackward0</text>\n</g>\n<!-- 139631144408112&#45;&gt;139631144667632 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139631144408112&#45;&gt;139631144667632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-66.79C103.5,-60.07 103.5,-50.4 103.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-41.19 103.5,-31.19 100,-41.19 107,-41.19\"/>\n</g>\n<!-- 139635006605296 -->\n<g id=\"node3\" class=\"node\">\n<title>139635006605296</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"169,-141 38,-141 38,-122 169,-122 169,-141\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">LogSoftmaxBackward0</text>\n</g>\n<!-- 139635006605296&#45;&gt;139631144408112 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139635006605296&#45;&gt;139631144408112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-121.75C103.5,-114.8 103.5,-104.85 103.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-96.09 103.5,-86.09 100,-96.09 107,-96.09\"/>\n</g>\n<!-- 139635290768912 -->\n<g id=\"node4\" class=\"node\">\n<title>139635290768912</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-196 53,-196 53,-177 154,-177 154,-196\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 139635290768912&#45;&gt;139635006605296 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139635290768912&#45;&gt;139635006605296</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-176.75C103.5,-169.8 103.5,-159.85 103.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-151.09 103.5,-141.09 100,-151.09 107,-151.09\"/>\n</g>\n<!-- 139631143573824 -->\n<g id=\"node5\" class=\"node\">\n<title>139631143573824</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139631143573824&#45;&gt;139635290768912 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139631143573824&#45;&gt;139635290768912</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.25,-231.75C66.97,-224.03 78.4,-212.6 87.72,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90.31,-205.64 94.91,-196.09 85.36,-200.69 90.31,-205.64\"/>\n</g>\n<!-- 139635290774800 -->\n<g id=\"node6\" class=\"node\">\n<title>139635290774800</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-317 21,-317 21,-287 80,-287 80,-317\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\">l1.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 139635290774800&#45;&gt;139631143573824 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139635290774800&#45;&gt;139631143573824</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.84C50.5,-279.21 50.5,-269.7 50.5,-261.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.27 50.5,-251.27 47,-261.27 54,-261.27\"/>\n</g>\n<!-- 139631143574784 -->\n<g id=\"node7\" class=\"node\">\n<title>139631143574784</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-251 119,-251 119,-232 196,-232 196,-251\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 139631143574784&#45;&gt;139635290768912 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139631143574784&#45;&gt;139635290768912</title>\n<path fill=\"none\" stroke=\"black\" d=\"M148.58,-231.75C140.72,-224.03 129.07,-212.6 119.58,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121.84,-200.6 112.25,-196.09 116.94,-205.59 121.84,-200.6\"/>\n</g>\n<!-- 139631143574832 -->\n<g id=\"node8\" class=\"node\">\n<title>139631143574832</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-311.5 107,-311.5 107,-292.5 208,-292.5 208,-311.5\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-299.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139631143574832&#45;&gt;139631143574784 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139631143574832&#45;&gt;139631143574784</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.5,-292.37C157.5,-284.25 157.5,-271.81 157.5,-261.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161,-261.17 157.5,-251.17 154,-261.17 161,-261.17\"/>\n</g>\n<!-- 139635147287824 -->\n<g id=\"node9\" class=\"node\">\n<title>139635147287824</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"193,-383 122,-383 122,-353 193,-353 193,-383\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">l1.weight</text>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\"> (3, 2)</text>\n</g>\n<!-- 139635147287824&#45;&gt;139631143574832 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139635147287824&#45;&gt;139631143574832</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.5,-352.8C157.5,-343.7 157.5,-331.79 157.5,-321.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161,-321.84 157.5,-311.84 154,-321.84 161,-321.84\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7eff5fe78730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 予測計算\n",
    "outputs = net(inputs)\n",
    "\n",
    "#  損失計算\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# 損失の計算グラフ可視化\n",
    "g = make_dot(loss, params=dict(net.named_parameters()))\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cbHG6zdB8wQ"
   },
   "source": [
    "### 予測ラベル値の取得方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.0000, 12.0000, 12.0000],\n",
      "        [12.7000, 12.7000, 12.7000],\n",
      "        [ 7.6000,  7.6000,  7.6000],\n",
      "        [13.0000, 13.0000, 13.0000],\n",
      "        [12.3000, 12.3000, 12.3000],\n",
      "        [ 7.6000,  7.6000,  7.6000],\n",
      "        [ 7.3000,  7.3000,  7.3000],\n",
      "        [11.1000, 11.1000, 11.1000],\n",
      "        [12.1000, 12.1000, 12.1000],\n",
      "        [13.3000, 13.3000, 13.3000],\n",
      "        [ 8.0000,  8.0000,  8.0000],\n",
      "        [ 7.0000,  7.0000,  7.0000],\n",
      "        [10.3000, 10.3000, 10.3000],\n",
      "        [ 7.6000,  7.6000,  7.6000],\n",
      "        [11.7000, 11.7000, 11.7000],\n",
      "        [13.3000, 13.3000, 13.3000],\n",
      "        [ 7.4000,  7.4000,  7.4000],\n",
      "        [13.5000, 13.5000, 13.5000],\n",
      "        [ 8.2000,  8.2000,  8.2000],\n",
      "        [ 8.4000,  8.4000,  8.4000],\n",
      "        [12.7000, 12.7000, 12.7000],\n",
      "        [ 6.6000,  6.6000,  6.6000],\n",
      "        [ 7.9000,  7.9000,  7.9000],\n",
      "        [12.2000, 12.2000, 12.2000],\n",
      "        [14.6000, 14.6000, 14.6000],\n",
      "        [12.0000, 12.0000, 12.0000],\n",
      "        [10.2000, 10.2000, 10.2000],\n",
      "        [10.5000, 10.5000, 10.5000],\n",
      "        [ 7.1000,  7.1000,  7.1000],\n",
      "        [ 7.3000,  7.3000,  7.3000],\n",
      "        [12.6000, 12.6000, 12.6000],\n",
      "        [12.7000, 12.7000, 12.7000],\n",
      "        [ 7.4000,  7.4000,  7.4000],\n",
      "        [ 7.7000,  7.7000,  7.7000],\n",
      "        [10.8000, 10.8000, 10.8000],\n",
      "        [11.5000, 11.5000, 11.5000],\n",
      "        [11.5000, 11.5000, 11.5000],\n",
      "        [14.0000, 14.0000, 14.0000],\n",
      "        [12.8000, 12.8000, 12.8000],\n",
      "        [10.8000, 10.8000, 10.8000],\n",
      "        [10.8000, 10.8000, 10.8000],\n",
      "        [15.2000, 15.2000, 15.2000],\n",
      "        [ 7.5000,  7.5000,  7.5000],\n",
      "        [ 7.8000,  7.8000,  7.8000],\n",
      "        [11.1000, 11.1000, 11.1000],\n",
      "        [13.6000, 13.6000, 13.6000],\n",
      "        [12.9000, 12.9000, 12.9000],\n",
      "        [14.2000, 14.2000, 14.2000],\n",
      "        [12.7000, 12.7000, 12.7000],\n",
      "        [ 7.6000,  7.6000,  7.6000],\n",
      "        [10.9000, 10.9000, 10.9000],\n",
      "        [ 7.0000,  7.0000,  7.0000],\n",
      "        [10.9000, 10.9000, 10.9000],\n",
      "        [11.2000, 11.2000, 11.2000],\n",
      "        [ 7.4000,  7.4000,  7.4000],\n",
      "        [11.7000, 11.7000, 11.7000],\n",
      "        [13.3000, 13.3000, 13.3000],\n",
      "        [11.5000, 11.5000, 11.5000],\n",
      "        [13.4000, 13.4000, 13.4000],\n",
      "        [12.7000, 12.7000, 12.7000],\n",
      "        [ 7.7000,  7.7000,  7.7000],\n",
      "        [11.8000, 11.8000, 11.8000],\n",
      "        [ 7.0000,  7.0000,  7.0000],\n",
      "        [12.6000, 12.6000, 12.6000],\n",
      "        [11.7000, 11.7000, 11.7000],\n",
      "        [10.9000, 10.9000, 10.9000],\n",
      "        [ 9.2000,  9.2000,  9.2000],\n",
      "        [12.2000, 12.2000, 12.2000],\n",
      "        [10.4000, 10.4000, 10.4000],\n",
      "        [12.1000, 12.1000, 12.1000],\n",
      "        [ 7.5000,  7.5000,  7.5000],\n",
      "        [ 9.1000,  9.1000,  9.1000],\n",
      "        [11.1000, 11.1000, 11.1000],\n",
      "        [12.0000, 12.0000, 12.0000],\n",
      "        [14.3000, 14.3000, 14.3000]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2fQ-IYOtB8wR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([12.0000, 12.7000,  7.6000, 13.0000, 12.3000,  7.6000,  7.3000, 11.1000,\n",
      "        12.1000, 13.3000,  8.0000,  7.0000, 10.3000,  7.6000, 11.7000, 13.3000,\n",
      "         7.4000, 13.5000,  8.2000,  8.4000, 12.7000,  6.6000,  7.9000, 12.2000,\n",
      "        14.6000, 12.0000, 10.2000, 10.5000,  7.1000,  7.3000, 12.6000, 12.7000,\n",
      "         7.4000,  7.7000, 10.8000, 11.5000, 11.5000, 14.0000, 12.8000, 10.8000,\n",
      "        10.8000, 15.2000,  7.5000,  7.8000, 11.1000, 13.6000, 12.9000, 14.2000,\n",
      "        12.7000,  7.6000, 10.9000,  7.0000, 10.9000, 11.2000,  7.4000, 11.7000,\n",
      "        13.3000, 11.5000, 13.4000, 12.7000,  7.7000, 11.8000,  7.0000, 12.6000,\n",
      "        11.7000, 10.9000,  9.2000, 12.2000, 10.4000, 12.1000,  7.5000,  9.1000,\n",
      "        11.1000, 12.0000, 14.3000], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# torch.max関数呼び出し\n",
    "# 2つめの引数は軸を意味している。1だと行ごとの集計。\n",
    "print(torch.max(outputs, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LYW8R14iB8wR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベル値の配列を取得\n",
    "torch.max(outputs, 1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUq1owdoB8wR"
   },
   "source": [
    "### 繰り返し計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "p6vnUjx8B8wR"
   },
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 初期化\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 損失関数： 交差エントロピー関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最適化関数: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 繰り返し回数\n",
    "num_epochs = 10000\n",
    "\n",
    "# 評価結果記録用\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dky9vOVqB8wR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09263, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.03580 acc: 0.40000 val_loss: 1.06403, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 1.00477 acc: 0.40000 val_loss: 1.03347, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.97672 acc: 0.40000 val_loss: 1.00264, val_acc: 0.26667\n",
      "Epoch [40/10000], loss: 0.95057 acc: 0.41333 val_loss: 0.97351, val_acc: 0.26667\n",
      "Epoch [50/10000], loss: 0.92616 acc: 0.48000 val_loss: 0.94631, val_acc: 0.38667\n",
      "Epoch [60/10000], loss: 0.90338 acc: 0.69333 val_loss: 0.92098, val_acc: 0.56000\n",
      "Epoch [70/10000], loss: 0.88212 acc: 0.70667 val_loss: 0.89740, val_acc: 0.60000\n",
      "Epoch [80/10000], loss: 0.86227 acc: 0.70667 val_loss: 0.87545, val_acc: 0.61333\n",
      "Epoch [90/10000], loss: 0.84373 acc: 0.70667 val_loss: 0.85500, val_acc: 0.62667\n",
      "Epoch [100/10000], loss: 0.82640 acc: 0.70667 val_loss: 0.83594, val_acc: 0.62667\n",
      "Epoch [110/10000], loss: 0.81019 acc: 0.72000 val_loss: 0.81815, val_acc: 0.62667\n",
      "Epoch [120/10000], loss: 0.79500 acc: 0.72000 val_loss: 0.80153, val_acc: 0.62667\n",
      "Epoch [130/10000], loss: 0.78077 acc: 0.73333 val_loss: 0.78599, val_acc: 0.62667\n",
      "Epoch [140/10000], loss: 0.76741 acc: 0.74667 val_loss: 0.77142, val_acc: 0.64000\n",
      "Epoch [150/10000], loss: 0.75485 acc: 0.74667 val_loss: 0.75777, val_acc: 0.65333\n",
      "Epoch [160/10000], loss: 0.74303 acc: 0.74667 val_loss: 0.74494, val_acc: 0.68000\n",
      "Epoch [170/10000], loss: 0.73189 acc: 0.76000 val_loss: 0.73288, val_acc: 0.70667\n",
      "Epoch [180/10000], loss: 0.72138 acc: 0.77333 val_loss: 0.72151, val_acc: 0.76000\n",
      "Epoch [190/10000], loss: 0.71145 acc: 0.82667 val_loss: 0.71079, val_acc: 0.78667\n",
      "Epoch [200/10000], loss: 0.70205 acc: 0.82667 val_loss: 0.70067, val_acc: 0.78667\n",
      "Epoch [210/10000], loss: 0.69315 acc: 0.84000 val_loss: 0.69109, val_acc: 0.80000\n",
      "Epoch [220/10000], loss: 0.68470 acc: 0.84000 val_loss: 0.68202, val_acc: 0.80000\n",
      "Epoch [230/10000], loss: 0.67667 acc: 0.86667 val_loss: 0.67341, val_acc: 0.81333\n",
      "Epoch [240/10000], loss: 0.66904 acc: 0.86667 val_loss: 0.66524, val_acc: 0.81333\n",
      "Epoch [250/10000], loss: 0.66176 acc: 0.86667 val_loss: 0.65746, val_acc: 0.82667\n",
      "Epoch [260/10000], loss: 0.65483 acc: 0.85333 val_loss: 0.65005, val_acc: 0.82667\n",
      "Epoch [270/10000], loss: 0.64820 acc: 0.85333 val_loss: 0.64299, val_acc: 0.82667\n",
      "Epoch [280/10000], loss: 0.64187 acc: 0.85333 val_loss: 0.63625, val_acc: 0.82667\n",
      "Epoch [290/10000], loss: 0.63581 acc: 0.86667 val_loss: 0.62980, val_acc: 0.82667\n",
      "Epoch [300/10000], loss: 0.63000 acc: 0.88000 val_loss: 0.62363, val_acc: 0.82667\n",
      "Epoch [310/10000], loss: 0.62443 acc: 0.89333 val_loss: 0.61772, val_acc: 0.82667\n",
      "Epoch [320/10000], loss: 0.61909 acc: 0.89333 val_loss: 0.61205, val_acc: 0.82667\n",
      "Epoch [330/10000], loss: 0.61394 acc: 0.89333 val_loss: 0.60661, val_acc: 0.82667\n",
      "Epoch [340/10000], loss: 0.60900 acc: 0.89333 val_loss: 0.60138, val_acc: 0.84000\n",
      "Epoch [350/10000], loss: 0.60423 acc: 0.89333 val_loss: 0.59635, val_acc: 0.84000\n",
      "Epoch [360/10000], loss: 0.59964 acc: 0.90667 val_loss: 0.59150, val_acc: 0.85333\n",
      "Epoch [370/10000], loss: 0.59521 acc: 0.92000 val_loss: 0.58683, val_acc: 0.86667\n",
      "Epoch [380/10000], loss: 0.59093 acc: 0.92000 val_loss: 0.58232, val_acc: 0.86667\n",
      "Epoch [390/10000], loss: 0.58679 acc: 0.92000 val_loss: 0.57797, val_acc: 0.86667\n",
      "Epoch [400/10000], loss: 0.58279 acc: 0.92000 val_loss: 0.57377, val_acc: 0.86667\n",
      "Epoch [410/10000], loss: 0.57891 acc: 0.92000 val_loss: 0.56970, val_acc: 0.86667\n",
      "Epoch [420/10000], loss: 0.57516 acc: 0.92000 val_loss: 0.56576, val_acc: 0.86667\n",
      "Epoch [430/10000], loss: 0.57152 acc: 0.90667 val_loss: 0.56195, val_acc: 0.86667\n",
      "Epoch [440/10000], loss: 0.56799 acc: 0.90667 val_loss: 0.55825, val_acc: 0.86667\n",
      "Epoch [450/10000], loss: 0.56456 acc: 0.90667 val_loss: 0.55466, val_acc: 0.86667\n",
      "Epoch [460/10000], loss: 0.56123 acc: 0.90667 val_loss: 0.55118, val_acc: 0.86667\n",
      "Epoch [470/10000], loss: 0.55799 acc: 0.90667 val_loss: 0.54779, val_acc: 0.88000\n",
      "Epoch [480/10000], loss: 0.55484 acc: 0.90667 val_loss: 0.54451, val_acc: 0.88000\n",
      "Epoch [490/10000], loss: 0.55177 acc: 0.90667 val_loss: 0.54131, val_acc: 0.88000\n",
      "Epoch [500/10000], loss: 0.54878 acc: 0.90667 val_loss: 0.53819, val_acc: 0.88000\n",
      "Epoch [510/10000], loss: 0.54587 acc: 0.90667 val_loss: 0.53516, val_acc: 0.88000\n",
      "Epoch [520/10000], loss: 0.54303 acc: 0.90667 val_loss: 0.53221, val_acc: 0.88000\n",
      "Epoch [530/10000], loss: 0.54026 acc: 0.90667 val_loss: 0.52933, val_acc: 0.88000\n",
      "Epoch [540/10000], loss: 0.53755 acc: 0.90667 val_loss: 0.52652, val_acc: 0.88000\n",
      "Epoch [550/10000], loss: 0.53491 acc: 0.90667 val_loss: 0.52377, val_acc: 0.88000\n",
      "Epoch [560/10000], loss: 0.53233 acc: 0.90667 val_loss: 0.52110, val_acc: 0.88000\n",
      "Epoch [570/10000], loss: 0.52981 acc: 0.90667 val_loss: 0.51848, val_acc: 0.88000\n",
      "Epoch [580/10000], loss: 0.52734 acc: 0.90667 val_loss: 0.51592, val_acc: 0.88000\n",
      "Epoch [590/10000], loss: 0.52493 acc: 0.90667 val_loss: 0.51342, val_acc: 0.88000\n",
      "Epoch [600/10000], loss: 0.52256 acc: 0.90667 val_loss: 0.51098, val_acc: 0.88000\n",
      "Epoch [610/10000], loss: 0.52025 acc: 0.90667 val_loss: 0.50859, val_acc: 0.88000\n",
      "Epoch [620/10000], loss: 0.51798 acc: 0.90667 val_loss: 0.50624, val_acc: 0.88000\n",
      "Epoch [630/10000], loss: 0.51576 acc: 0.90667 val_loss: 0.50395, val_acc: 0.88000\n",
      "Epoch [640/10000], loss: 0.51358 acc: 0.90667 val_loss: 0.50170, val_acc: 0.88000\n",
      "Epoch [650/10000], loss: 0.51144 acc: 0.90667 val_loss: 0.49949, val_acc: 0.88000\n",
      "Epoch [660/10000], loss: 0.50934 acc: 0.90667 val_loss: 0.49733, val_acc: 0.89333\n",
      "Epoch [670/10000], loss: 0.50728 acc: 0.90667 val_loss: 0.49521, val_acc: 0.90667\n",
      "Epoch [680/10000], loss: 0.50526 acc: 0.90667 val_loss: 0.49313, val_acc: 0.90667\n",
      "Epoch [690/10000], loss: 0.50328 acc: 0.90667 val_loss: 0.49109, val_acc: 0.90667\n",
      "Epoch [700/10000], loss: 0.50133 acc: 0.90667 val_loss: 0.48908, val_acc: 0.90667\n",
      "Epoch [710/10000], loss: 0.49941 acc: 0.90667 val_loss: 0.48711, val_acc: 0.90667\n",
      "Epoch [720/10000], loss: 0.49752 acc: 0.90667 val_loss: 0.48517, val_acc: 0.90667\n",
      "Epoch [730/10000], loss: 0.49567 acc: 0.90667 val_loss: 0.48327, val_acc: 0.90667\n",
      "Epoch [740/10000], loss: 0.49385 acc: 0.90667 val_loss: 0.48140, val_acc: 0.90667\n",
      "Epoch [750/10000], loss: 0.49205 acc: 0.90667 val_loss: 0.47956, val_acc: 0.90667\n",
      "Epoch [760/10000], loss: 0.49029 acc: 0.90667 val_loss: 0.47775, val_acc: 0.90667\n",
      "Epoch [770/10000], loss: 0.48855 acc: 0.90667 val_loss: 0.47597, val_acc: 0.90667\n",
      "Epoch [780/10000], loss: 0.48684 acc: 0.90667 val_loss: 0.47422, val_acc: 0.90667\n",
      "Epoch [790/10000], loss: 0.48515 acc: 0.89333 val_loss: 0.47249, val_acc: 0.92000\n",
      "Epoch [800/10000], loss: 0.48349 acc: 0.89333 val_loss: 0.47079, val_acc: 0.92000\n",
      "Epoch [810/10000], loss: 0.48186 acc: 0.89333 val_loss: 0.46912, val_acc: 0.92000\n",
      "Epoch [820/10000], loss: 0.48024 acc: 0.89333 val_loss: 0.46747, val_acc: 0.92000\n",
      "Epoch [830/10000], loss: 0.47865 acc: 0.89333 val_loss: 0.46585, val_acc: 0.92000\n",
      "Epoch [840/10000], loss: 0.47709 acc: 0.89333 val_loss: 0.46425, val_acc: 0.92000\n",
      "Epoch [850/10000], loss: 0.47554 acc: 0.89333 val_loss: 0.46267, val_acc: 0.92000\n",
      "Epoch [860/10000], loss: 0.47402 acc: 0.89333 val_loss: 0.46111, val_acc: 0.92000\n",
      "Epoch [870/10000], loss: 0.47251 acc: 0.89333 val_loss: 0.45958, val_acc: 0.92000\n",
      "Epoch [880/10000], loss: 0.47103 acc: 0.89333 val_loss: 0.45806, val_acc: 0.92000\n",
      "Epoch [890/10000], loss: 0.46956 acc: 0.89333 val_loss: 0.45657, val_acc: 0.92000\n",
      "Epoch [900/10000], loss: 0.46811 acc: 0.89333 val_loss: 0.45509, val_acc: 0.92000\n",
      "Epoch [910/10000], loss: 0.46668 acc: 0.89333 val_loss: 0.45364, val_acc: 0.92000\n",
      "Epoch [920/10000], loss: 0.46527 acc: 0.89333 val_loss: 0.45220, val_acc: 0.92000\n",
      "Epoch [930/10000], loss: 0.46388 acc: 0.89333 val_loss: 0.45078, val_acc: 0.92000\n",
      "Epoch [940/10000], loss: 0.46250 acc: 0.89333 val_loss: 0.44938, val_acc: 0.92000\n",
      "Epoch [950/10000], loss: 0.46114 acc: 0.89333 val_loss: 0.44800, val_acc: 0.92000\n",
      "Epoch [960/10000], loss: 0.45980 acc: 0.89333 val_loss: 0.44663, val_acc: 0.92000\n",
      "Epoch [970/10000], loss: 0.45847 acc: 0.89333 val_loss: 0.44528, val_acc: 0.92000\n",
      "Epoch [980/10000], loss: 0.45716 acc: 0.89333 val_loss: 0.44395, val_acc: 0.92000\n",
      "Epoch [990/10000], loss: 0.45586 acc: 0.89333 val_loss: 0.44263, val_acc: 0.92000\n",
      "Epoch [1000/10000], loss: 0.45458 acc: 0.89333 val_loss: 0.44133, val_acc: 0.92000\n",
      "Epoch [1010/10000], loss: 0.45331 acc: 0.89333 val_loss: 0.44004, val_acc: 0.92000\n",
      "Epoch [1020/10000], loss: 0.45205 acc: 0.89333 val_loss: 0.43877, val_acc: 0.92000\n",
      "Epoch [1030/10000], loss: 0.45081 acc: 0.89333 val_loss: 0.43751, val_acc: 0.92000\n",
      "Epoch [1040/10000], loss: 0.44958 acc: 0.89333 val_loss: 0.43626, val_acc: 0.92000\n",
      "Epoch [1050/10000], loss: 0.44836 acc: 0.89333 val_loss: 0.43503, val_acc: 0.92000\n",
      "Epoch [1060/10000], loss: 0.44716 acc: 0.89333 val_loss: 0.43381, val_acc: 0.92000\n",
      "Epoch [1070/10000], loss: 0.44597 acc: 0.89333 val_loss: 0.43260, val_acc: 0.92000\n",
      "Epoch [1080/10000], loss: 0.44479 acc: 0.89333 val_loss: 0.43141, val_acc: 0.92000\n",
      "Epoch [1090/10000], loss: 0.44363 acc: 0.89333 val_loss: 0.43023, val_acc: 0.92000\n",
      "Epoch [1100/10000], loss: 0.44247 acc: 0.89333 val_loss: 0.42906, val_acc: 0.92000\n",
      "Epoch [1110/10000], loss: 0.44133 acc: 0.89333 val_loss: 0.42790, val_acc: 0.92000\n",
      "Epoch [1120/10000], loss: 0.44020 acc: 0.89333 val_loss: 0.42676, val_acc: 0.92000\n",
      "Epoch [1130/10000], loss: 0.43908 acc: 0.89333 val_loss: 0.42562, val_acc: 0.92000\n",
      "Epoch [1140/10000], loss: 0.43797 acc: 0.89333 val_loss: 0.42450, val_acc: 0.92000\n",
      "Epoch [1150/10000], loss: 0.43687 acc: 0.89333 val_loss: 0.42339, val_acc: 0.92000\n",
      "Epoch [1160/10000], loss: 0.43578 acc: 0.89333 val_loss: 0.42229, val_acc: 0.92000\n",
      "Epoch [1170/10000], loss: 0.43470 acc: 0.89333 val_loss: 0.42120, val_acc: 0.92000\n",
      "Epoch [1180/10000], loss: 0.43363 acc: 0.89333 val_loss: 0.42012, val_acc: 0.92000\n",
      "Epoch [1190/10000], loss: 0.43257 acc: 0.89333 val_loss: 0.41905, val_acc: 0.92000\n",
      "Epoch [1200/10000], loss: 0.43152 acc: 0.89333 val_loss: 0.41799, val_acc: 0.92000\n",
      "Epoch [1210/10000], loss: 0.43048 acc: 0.89333 val_loss: 0.41694, val_acc: 0.92000\n",
      "Epoch [1220/10000], loss: 0.42945 acc: 0.89333 val_loss: 0.41590, val_acc: 0.92000\n",
      "Epoch [1230/10000], loss: 0.42843 acc: 0.89333 val_loss: 0.41487, val_acc: 0.92000\n",
      "Epoch [1240/10000], loss: 0.42742 acc: 0.89333 val_loss: 0.41384, val_acc: 0.92000\n",
      "Epoch [1250/10000], loss: 0.42641 acc: 0.89333 val_loss: 0.41283, val_acc: 0.92000\n",
      "Epoch [1260/10000], loss: 0.42542 acc: 0.89333 val_loss: 0.41182, val_acc: 0.92000\n",
      "Epoch [1270/10000], loss: 0.42443 acc: 0.89333 val_loss: 0.41083, val_acc: 0.92000\n",
      "Epoch [1280/10000], loss: 0.42345 acc: 0.89333 val_loss: 0.40984, val_acc: 0.92000\n",
      "Epoch [1290/10000], loss: 0.42248 acc: 0.89333 val_loss: 0.40886, val_acc: 0.92000\n",
      "Epoch [1300/10000], loss: 0.42152 acc: 0.89333 val_loss: 0.40789, val_acc: 0.92000\n",
      "Epoch [1310/10000], loss: 0.42056 acc: 0.89333 val_loss: 0.40693, val_acc: 0.92000\n",
      "Epoch [1320/10000], loss: 0.41962 acc: 0.89333 val_loss: 0.40598, val_acc: 0.92000\n",
      "Epoch [1330/10000], loss: 0.41868 acc: 0.89333 val_loss: 0.40503, val_acc: 0.93333\n",
      "Epoch [1340/10000], loss: 0.41775 acc: 0.89333 val_loss: 0.40409, val_acc: 0.93333\n",
      "Epoch [1350/10000], loss: 0.41682 acc: 0.89333 val_loss: 0.40316, val_acc: 0.93333\n",
      "Epoch [1360/10000], loss: 0.41590 acc: 0.89333 val_loss: 0.40224, val_acc: 0.93333\n",
      "Epoch [1370/10000], loss: 0.41499 acc: 0.89333 val_loss: 0.40132, val_acc: 0.93333\n",
      "Epoch [1380/10000], loss: 0.41409 acc: 0.89333 val_loss: 0.40041, val_acc: 0.93333\n",
      "Epoch [1390/10000], loss: 0.41320 acc: 0.89333 val_loss: 0.39951, val_acc: 0.93333\n",
      "Epoch [1400/10000], loss: 0.41231 acc: 0.89333 val_loss: 0.39861, val_acc: 0.93333\n",
      "Epoch [1410/10000], loss: 0.41143 acc: 0.89333 val_loss: 0.39773, val_acc: 0.93333\n",
      "Epoch [1420/10000], loss: 0.41055 acc: 0.89333 val_loss: 0.39685, val_acc: 0.93333\n",
      "Epoch [1430/10000], loss: 0.40968 acc: 0.89333 val_loss: 0.39597, val_acc: 0.93333\n",
      "Epoch [1440/10000], loss: 0.40882 acc: 0.89333 val_loss: 0.39510, val_acc: 0.93333\n",
      "Epoch [1450/10000], loss: 0.40796 acc: 0.89333 val_loss: 0.39424, val_acc: 0.93333\n",
      "Epoch [1460/10000], loss: 0.40711 acc: 0.89333 val_loss: 0.39339, val_acc: 0.93333\n",
      "Epoch [1470/10000], loss: 0.40627 acc: 0.89333 val_loss: 0.39254, val_acc: 0.93333\n",
      "Epoch [1480/10000], loss: 0.40543 acc: 0.90667 val_loss: 0.39170, val_acc: 0.93333\n",
      "Epoch [1490/10000], loss: 0.40460 acc: 0.90667 val_loss: 0.39086, val_acc: 0.93333\n",
      "Epoch [1500/10000], loss: 0.40378 acc: 0.90667 val_loss: 0.39003, val_acc: 0.93333\n",
      "Epoch [1510/10000], loss: 0.40296 acc: 0.90667 val_loss: 0.38921, val_acc: 0.93333\n",
      "Epoch [1520/10000], loss: 0.40214 acc: 0.90667 val_loss: 0.38839, val_acc: 0.93333\n",
      "Epoch [1530/10000], loss: 0.40134 acc: 0.90667 val_loss: 0.38758, val_acc: 0.93333\n",
      "Epoch [1540/10000], loss: 0.40053 acc: 0.90667 val_loss: 0.38677, val_acc: 0.93333\n",
      "Epoch [1550/10000], loss: 0.39974 acc: 0.90667 val_loss: 0.38597, val_acc: 0.93333\n",
      "Epoch [1560/10000], loss: 0.39894 acc: 0.90667 val_loss: 0.38517, val_acc: 0.94667\n",
      "Epoch [1570/10000], loss: 0.39816 acc: 0.90667 val_loss: 0.38438, val_acc: 0.94667\n",
      "Epoch [1580/10000], loss: 0.39738 acc: 0.90667 val_loss: 0.38360, val_acc: 0.94667\n",
      "Epoch [1590/10000], loss: 0.39660 acc: 0.90667 val_loss: 0.38282, val_acc: 0.94667\n",
      "Epoch [1600/10000], loss: 0.39583 acc: 0.90667 val_loss: 0.38204, val_acc: 0.94667\n",
      "Epoch [1610/10000], loss: 0.39507 acc: 0.90667 val_loss: 0.38128, val_acc: 0.94667\n",
      "Epoch [1620/10000], loss: 0.39431 acc: 0.90667 val_loss: 0.38051, val_acc: 0.94667\n",
      "Epoch [1630/10000], loss: 0.39355 acc: 0.90667 val_loss: 0.37975, val_acc: 0.94667\n",
      "Epoch [1640/10000], loss: 0.39280 acc: 0.90667 val_loss: 0.37900, val_acc: 0.94667\n",
      "Epoch [1650/10000], loss: 0.39206 acc: 0.90667 val_loss: 0.37825, val_acc: 0.94667\n",
      "Epoch [1660/10000], loss: 0.39132 acc: 0.90667 val_loss: 0.37751, val_acc: 0.94667\n",
      "Epoch [1670/10000], loss: 0.39058 acc: 0.90667 val_loss: 0.37677, val_acc: 0.94667\n",
      "Epoch [1680/10000], loss: 0.38985 acc: 0.90667 val_loss: 0.37604, val_acc: 0.94667\n",
      "Epoch [1690/10000], loss: 0.38913 acc: 0.90667 val_loss: 0.37531, val_acc: 0.94667\n",
      "Epoch [1700/10000], loss: 0.38841 acc: 0.90667 val_loss: 0.37458, val_acc: 0.94667\n",
      "Epoch [1710/10000], loss: 0.38769 acc: 0.90667 val_loss: 0.37386, val_acc: 0.94667\n",
      "Epoch [1720/10000], loss: 0.38698 acc: 0.90667 val_loss: 0.37315, val_acc: 0.94667\n",
      "Epoch [1730/10000], loss: 0.38627 acc: 0.90667 val_loss: 0.37244, val_acc: 0.94667\n",
      "Epoch [1740/10000], loss: 0.38557 acc: 0.90667 val_loss: 0.37173, val_acc: 0.94667\n",
      "Epoch [1750/10000], loss: 0.38487 acc: 0.90667 val_loss: 0.37103, val_acc: 0.94667\n",
      "Epoch [1760/10000], loss: 0.38417 acc: 0.90667 val_loss: 0.37033, val_acc: 0.94667\n",
      "Epoch [1770/10000], loss: 0.38348 acc: 0.90667 val_loss: 0.36964, val_acc: 0.94667\n",
      "Epoch [1780/10000], loss: 0.38280 acc: 0.90667 val_loss: 0.36895, val_acc: 0.94667\n",
      "Epoch [1790/10000], loss: 0.38212 acc: 0.90667 val_loss: 0.36826, val_acc: 0.94667\n",
      "Epoch [1800/10000], loss: 0.38144 acc: 0.90667 val_loss: 0.36758, val_acc: 0.94667\n",
      "Epoch [1810/10000], loss: 0.38076 acc: 0.90667 val_loss: 0.36690, val_acc: 0.94667\n",
      "Epoch [1820/10000], loss: 0.38009 acc: 0.90667 val_loss: 0.36623, val_acc: 0.94667\n",
      "Epoch [1830/10000], loss: 0.37943 acc: 0.90667 val_loss: 0.36556, val_acc: 0.94667\n",
      "Epoch [1840/10000], loss: 0.37877 acc: 0.90667 val_loss: 0.36490, val_acc: 0.94667\n",
      "Epoch [1850/10000], loss: 0.37811 acc: 0.90667 val_loss: 0.36424, val_acc: 0.94667\n",
      "Epoch [1860/10000], loss: 0.37746 acc: 0.90667 val_loss: 0.36358, val_acc: 0.94667\n",
      "Epoch [1870/10000], loss: 0.37681 acc: 0.90667 val_loss: 0.36293, val_acc: 0.94667\n",
      "Epoch [1880/10000], loss: 0.37616 acc: 0.90667 val_loss: 0.36228, val_acc: 0.94667\n",
      "Epoch [1890/10000], loss: 0.37552 acc: 0.90667 val_loss: 0.36163, val_acc: 0.94667\n",
      "Epoch [1900/10000], loss: 0.37488 acc: 0.90667 val_loss: 0.36099, val_acc: 0.94667\n",
      "Epoch [1910/10000], loss: 0.37424 acc: 0.90667 val_loss: 0.36035, val_acc: 0.94667\n",
      "Epoch [1920/10000], loss: 0.37361 acc: 0.90667 val_loss: 0.35972, val_acc: 0.94667\n",
      "Epoch [1930/10000], loss: 0.37298 acc: 0.90667 val_loss: 0.35909, val_acc: 0.94667\n",
      "Epoch [1940/10000], loss: 0.37236 acc: 0.90667 val_loss: 0.35846, val_acc: 0.94667\n",
      "Epoch [1950/10000], loss: 0.37174 acc: 0.90667 val_loss: 0.35784, val_acc: 0.94667\n",
      "Epoch [1960/10000], loss: 0.37112 acc: 0.90667 val_loss: 0.35722, val_acc: 0.94667\n",
      "Epoch [1970/10000], loss: 0.37051 acc: 0.90667 val_loss: 0.35660, val_acc: 0.94667\n",
      "Epoch [1980/10000], loss: 0.36990 acc: 0.90667 val_loss: 0.35599, val_acc: 0.94667\n",
      "Epoch [1990/10000], loss: 0.36929 acc: 0.90667 val_loss: 0.35538, val_acc: 0.94667\n",
      "Epoch [2000/10000], loss: 0.36869 acc: 0.90667 val_loss: 0.35477, val_acc: 0.94667\n",
      "Epoch [2010/10000], loss: 0.36809 acc: 0.90667 val_loss: 0.35417, val_acc: 0.94667\n",
      "Epoch [2020/10000], loss: 0.36749 acc: 0.90667 val_loss: 0.35357, val_acc: 0.94667\n",
      "Epoch [2030/10000], loss: 0.36690 acc: 0.90667 val_loss: 0.35298, val_acc: 0.94667\n",
      "Epoch [2040/10000], loss: 0.36631 acc: 0.90667 val_loss: 0.35238, val_acc: 0.94667\n",
      "Epoch [2050/10000], loss: 0.36572 acc: 0.90667 val_loss: 0.35179, val_acc: 0.94667\n",
      "Epoch [2060/10000], loss: 0.36514 acc: 0.90667 val_loss: 0.35121, val_acc: 0.94667\n",
      "Epoch [2070/10000], loss: 0.36455 acc: 0.90667 val_loss: 0.35062, val_acc: 0.94667\n",
      "Epoch [2080/10000], loss: 0.36398 acc: 0.90667 val_loss: 0.35004, val_acc: 0.94667\n",
      "Epoch [2090/10000], loss: 0.36340 acc: 0.90667 val_loss: 0.34947, val_acc: 0.94667\n",
      "Epoch [2100/10000], loss: 0.36283 acc: 0.90667 val_loss: 0.34889, val_acc: 0.94667\n",
      "Epoch [2110/10000], loss: 0.36226 acc: 0.90667 val_loss: 0.34832, val_acc: 0.94667\n",
      "Epoch [2120/10000], loss: 0.36170 acc: 0.90667 val_loss: 0.34775, val_acc: 0.94667\n",
      "Epoch [2130/10000], loss: 0.36114 acc: 0.90667 val_loss: 0.34719, val_acc: 0.94667\n",
      "Epoch [2140/10000], loss: 0.36058 acc: 0.90667 val_loss: 0.34663, val_acc: 0.94667\n",
      "Epoch [2150/10000], loss: 0.36002 acc: 0.90667 val_loss: 0.34607, val_acc: 0.94667\n",
      "Epoch [2160/10000], loss: 0.35947 acc: 0.90667 val_loss: 0.34551, val_acc: 0.94667\n",
      "Epoch [2170/10000], loss: 0.35892 acc: 0.90667 val_loss: 0.34496, val_acc: 0.94667\n",
      "Epoch [2180/10000], loss: 0.35837 acc: 0.90667 val_loss: 0.34441, val_acc: 0.94667\n",
      "Epoch [2190/10000], loss: 0.35782 acc: 0.90667 val_loss: 0.34386, val_acc: 0.94667\n",
      "Epoch [2200/10000], loss: 0.35728 acc: 0.90667 val_loss: 0.34331, val_acc: 0.94667\n",
      "Epoch [2210/10000], loss: 0.35674 acc: 0.90667 val_loss: 0.34277, val_acc: 0.94667\n",
      "Epoch [2220/10000], loss: 0.35621 acc: 0.90667 val_loss: 0.34223, val_acc: 0.94667\n",
      "Epoch [2230/10000], loss: 0.35567 acc: 0.90667 val_loss: 0.34170, val_acc: 0.94667\n",
      "Epoch [2240/10000], loss: 0.35514 acc: 0.90667 val_loss: 0.34116, val_acc: 0.94667\n",
      "Epoch [2250/10000], loss: 0.35461 acc: 0.90667 val_loss: 0.34063, val_acc: 0.94667\n",
      "Epoch [2260/10000], loss: 0.35409 acc: 0.90667 val_loss: 0.34010, val_acc: 0.94667\n",
      "Epoch [2270/10000], loss: 0.35356 acc: 0.90667 val_loss: 0.33958, val_acc: 0.94667\n",
      "Epoch [2280/10000], loss: 0.35304 acc: 0.90667 val_loss: 0.33905, val_acc: 0.94667\n",
      "Epoch [2290/10000], loss: 0.35253 acc: 0.90667 val_loss: 0.33853, val_acc: 0.94667\n",
      "Epoch [2300/10000], loss: 0.35201 acc: 0.90667 val_loss: 0.33802, val_acc: 0.94667\n",
      "Epoch [2310/10000], loss: 0.35150 acc: 0.90667 val_loss: 0.33750, val_acc: 0.94667\n",
      "Epoch [2320/10000], loss: 0.35099 acc: 0.90667 val_loss: 0.33699, val_acc: 0.94667\n",
      "Epoch [2330/10000], loss: 0.35048 acc: 0.90667 val_loss: 0.33648, val_acc: 0.94667\n",
      "Epoch [2340/10000], loss: 0.34998 acc: 0.90667 val_loss: 0.33597, val_acc: 0.94667\n",
      "Epoch [2350/10000], loss: 0.34947 acc: 0.90667 val_loss: 0.33546, val_acc: 0.94667\n",
      "Epoch [2360/10000], loss: 0.34897 acc: 0.90667 val_loss: 0.33496, val_acc: 0.94667\n",
      "Epoch [2370/10000], loss: 0.34848 acc: 0.90667 val_loss: 0.33446, val_acc: 0.94667\n",
      "Epoch [2380/10000], loss: 0.34798 acc: 0.90667 val_loss: 0.33396, val_acc: 0.94667\n",
      "Epoch [2390/10000], loss: 0.34749 acc: 0.90667 val_loss: 0.33347, val_acc: 0.94667\n",
      "Epoch [2400/10000], loss: 0.34700 acc: 0.90667 val_loss: 0.33297, val_acc: 0.94667\n",
      "Epoch [2410/10000], loss: 0.34651 acc: 0.90667 val_loss: 0.33248, val_acc: 0.94667\n",
      "Epoch [2420/10000], loss: 0.34602 acc: 0.90667 val_loss: 0.33199, val_acc: 0.94667\n",
      "Epoch [2430/10000], loss: 0.34554 acc: 0.90667 val_loss: 0.33151, val_acc: 0.94667\n",
      "Epoch [2440/10000], loss: 0.34506 acc: 0.90667 val_loss: 0.33102, val_acc: 0.94667\n",
      "Epoch [2450/10000], loss: 0.34458 acc: 0.90667 val_loss: 0.33054, val_acc: 0.94667\n",
      "Epoch [2460/10000], loss: 0.34411 acc: 0.90667 val_loss: 0.33006, val_acc: 0.94667\n",
      "Epoch [2470/10000], loss: 0.34363 acc: 0.90667 val_loss: 0.32959, val_acc: 0.94667\n",
      "Epoch [2480/10000], loss: 0.34316 acc: 0.90667 val_loss: 0.32911, val_acc: 0.94667\n",
      "Epoch [2490/10000], loss: 0.34269 acc: 0.90667 val_loss: 0.32864, val_acc: 0.94667\n",
      "Epoch [2500/10000], loss: 0.34222 acc: 0.90667 val_loss: 0.32817, val_acc: 0.94667\n",
      "Epoch [2510/10000], loss: 0.34176 acc: 0.90667 val_loss: 0.32770, val_acc: 0.94667\n",
      "Epoch [2520/10000], loss: 0.34130 acc: 0.90667 val_loss: 0.32723, val_acc: 0.94667\n",
      "Epoch [2530/10000], loss: 0.34083 acc: 0.90667 val_loss: 0.32677, val_acc: 0.94667\n",
      "Epoch [2540/10000], loss: 0.34038 acc: 0.90667 val_loss: 0.32631, val_acc: 0.94667\n",
      "Epoch [2550/10000], loss: 0.33992 acc: 0.90667 val_loss: 0.32585, val_acc: 0.94667\n",
      "Epoch [2560/10000], loss: 0.33947 acc: 0.90667 val_loss: 0.32539, val_acc: 0.94667\n",
      "Epoch [2570/10000], loss: 0.33901 acc: 0.90667 val_loss: 0.32493, val_acc: 0.94667\n",
      "Epoch [2580/10000], loss: 0.33856 acc: 0.90667 val_loss: 0.32448, val_acc: 0.94667\n",
      "Epoch [2590/10000], loss: 0.33812 acc: 0.90667 val_loss: 0.32403, val_acc: 0.94667\n",
      "Epoch [2600/10000], loss: 0.33767 acc: 0.90667 val_loss: 0.32358, val_acc: 0.94667\n",
      "Epoch [2610/10000], loss: 0.33723 acc: 0.90667 val_loss: 0.32313, val_acc: 0.94667\n",
      "Epoch [2620/10000], loss: 0.33678 acc: 0.90667 val_loss: 0.32269, val_acc: 0.94667\n",
      "Epoch [2630/10000], loss: 0.33634 acc: 0.90667 val_loss: 0.32225, val_acc: 0.94667\n",
      "Epoch [2640/10000], loss: 0.33591 acc: 0.90667 val_loss: 0.32180, val_acc: 0.94667\n",
      "Epoch [2650/10000], loss: 0.33547 acc: 0.90667 val_loss: 0.32136, val_acc: 0.94667\n",
      "Epoch [2660/10000], loss: 0.33504 acc: 0.90667 val_loss: 0.32093, val_acc: 0.94667\n",
      "Epoch [2670/10000], loss: 0.33460 acc: 0.90667 val_loss: 0.32049, val_acc: 0.94667\n",
      "Epoch [2680/10000], loss: 0.33417 acc: 0.90667 val_loss: 0.32006, val_acc: 0.94667\n",
      "Epoch [2690/10000], loss: 0.33375 acc: 0.90667 val_loss: 0.31963, val_acc: 0.94667\n",
      "Epoch [2700/10000], loss: 0.33332 acc: 0.90667 val_loss: 0.31920, val_acc: 0.94667\n",
      "Epoch [2710/10000], loss: 0.33290 acc: 0.90667 val_loss: 0.31877, val_acc: 0.94667\n",
      "Epoch [2720/10000], loss: 0.33247 acc: 0.90667 val_loss: 0.31834, val_acc: 0.94667\n",
      "Epoch [2730/10000], loss: 0.33205 acc: 0.90667 val_loss: 0.31792, val_acc: 0.94667\n",
      "Epoch [2740/10000], loss: 0.33164 acc: 0.90667 val_loss: 0.31750, val_acc: 0.94667\n",
      "Epoch [2750/10000], loss: 0.33122 acc: 0.90667 val_loss: 0.31708, val_acc: 0.94667\n",
      "Epoch [2760/10000], loss: 0.33080 acc: 0.90667 val_loss: 0.31666, val_acc: 0.94667\n",
      "Epoch [2770/10000], loss: 0.33039 acc: 0.90667 val_loss: 0.31624, val_acc: 0.94667\n",
      "Epoch [2780/10000], loss: 0.32998 acc: 0.90667 val_loss: 0.31583, val_acc: 0.94667\n",
      "Epoch [2790/10000], loss: 0.32957 acc: 0.90667 val_loss: 0.31542, val_acc: 0.94667\n",
      "Epoch [2800/10000], loss: 0.32916 acc: 0.90667 val_loss: 0.31500, val_acc: 0.94667\n",
      "Epoch [2810/10000], loss: 0.32876 acc: 0.90667 val_loss: 0.31460, val_acc: 0.94667\n",
      "Epoch [2820/10000], loss: 0.32835 acc: 0.90667 val_loss: 0.31419, val_acc: 0.94667\n",
      "Epoch [2830/10000], loss: 0.32795 acc: 0.90667 val_loss: 0.31378, val_acc: 0.94667\n",
      "Epoch [2840/10000], loss: 0.32755 acc: 0.90667 val_loss: 0.31338, val_acc: 0.94667\n",
      "Epoch [2850/10000], loss: 0.32715 acc: 0.90667 val_loss: 0.31297, val_acc: 0.94667\n",
      "Epoch [2860/10000], loss: 0.32675 acc: 0.90667 val_loss: 0.31257, val_acc: 0.94667\n",
      "Epoch [2870/10000], loss: 0.32636 acc: 0.90667 val_loss: 0.31217, val_acc: 0.94667\n",
      "Epoch [2880/10000], loss: 0.32597 acc: 0.90667 val_loss: 0.31178, val_acc: 0.94667\n",
      "Epoch [2890/10000], loss: 0.32557 acc: 0.90667 val_loss: 0.31138, val_acc: 0.94667\n",
      "Epoch [2900/10000], loss: 0.32518 acc: 0.90667 val_loss: 0.31099, val_acc: 0.94667\n",
      "Epoch [2910/10000], loss: 0.32480 acc: 0.90667 val_loss: 0.31060, val_acc: 0.94667\n",
      "Epoch [2920/10000], loss: 0.32441 acc: 0.90667 val_loss: 0.31020, val_acc: 0.94667\n",
      "Epoch [2930/10000], loss: 0.32402 acc: 0.90667 val_loss: 0.30982, val_acc: 0.94667\n",
      "Epoch [2940/10000], loss: 0.32364 acc: 0.90667 val_loss: 0.30943, val_acc: 0.94667\n",
      "Epoch [2950/10000], loss: 0.32326 acc: 0.90667 val_loss: 0.30904, val_acc: 0.94667\n",
      "Epoch [2960/10000], loss: 0.32288 acc: 0.90667 val_loss: 0.30866, val_acc: 0.94667\n",
      "Epoch [2970/10000], loss: 0.32250 acc: 0.90667 val_loss: 0.30827, val_acc: 0.94667\n",
      "Epoch [2980/10000], loss: 0.32212 acc: 0.90667 val_loss: 0.30789, val_acc: 0.94667\n",
      "Epoch [2990/10000], loss: 0.32175 acc: 0.90667 val_loss: 0.30751, val_acc: 0.94667\n",
      "Epoch [3000/10000], loss: 0.32137 acc: 0.90667 val_loss: 0.30714, val_acc: 0.94667\n",
      "Epoch [3010/10000], loss: 0.32100 acc: 0.90667 val_loss: 0.30676, val_acc: 0.94667\n",
      "Epoch [3020/10000], loss: 0.32063 acc: 0.90667 val_loss: 0.30638, val_acc: 0.94667\n",
      "Epoch [3030/10000], loss: 0.32026 acc: 0.90667 val_loss: 0.30601, val_acc: 0.94667\n",
      "Epoch [3040/10000], loss: 0.31989 acc: 0.90667 val_loss: 0.30564, val_acc: 0.94667\n",
      "Epoch [3050/10000], loss: 0.31952 acc: 0.90667 val_loss: 0.30527, val_acc: 0.94667\n",
      "Epoch [3060/10000], loss: 0.31916 acc: 0.90667 val_loss: 0.30490, val_acc: 0.94667\n",
      "Epoch [3070/10000], loss: 0.31880 acc: 0.90667 val_loss: 0.30453, val_acc: 0.94667\n",
      "Epoch [3080/10000], loss: 0.31844 acc: 0.90667 val_loss: 0.30417, val_acc: 0.94667\n",
      "Epoch [3090/10000], loss: 0.31807 acc: 0.90667 val_loss: 0.30380, val_acc: 0.94667\n",
      "Epoch [3100/10000], loss: 0.31772 acc: 0.90667 val_loss: 0.30344, val_acc: 0.94667\n",
      "Epoch [3110/10000], loss: 0.31736 acc: 0.90667 val_loss: 0.30308, val_acc: 0.94667\n",
      "Epoch [3120/10000], loss: 0.31700 acc: 0.90667 val_loss: 0.30272, val_acc: 0.94667\n",
      "Epoch [3130/10000], loss: 0.31665 acc: 0.90667 val_loss: 0.30236, val_acc: 0.94667\n",
      "Epoch [3140/10000], loss: 0.31630 acc: 0.90667 val_loss: 0.30200, val_acc: 0.94667\n",
      "Epoch [3150/10000], loss: 0.31594 acc: 0.90667 val_loss: 0.30165, val_acc: 0.94667\n",
      "Epoch [3160/10000], loss: 0.31559 acc: 0.90667 val_loss: 0.30129, val_acc: 0.94667\n",
      "Epoch [3170/10000], loss: 0.31525 acc: 0.90667 val_loss: 0.30094, val_acc: 0.94667\n",
      "Epoch [3180/10000], loss: 0.31490 acc: 0.90667 val_loss: 0.30059, val_acc: 0.94667\n",
      "Epoch [3190/10000], loss: 0.31455 acc: 0.90667 val_loss: 0.30024, val_acc: 0.94667\n",
      "Epoch [3200/10000], loss: 0.31421 acc: 0.90667 val_loss: 0.29989, val_acc: 0.94667\n",
      "Epoch [3210/10000], loss: 0.31386 acc: 0.90667 val_loss: 0.29954, val_acc: 0.94667\n",
      "Epoch [3220/10000], loss: 0.31352 acc: 0.90667 val_loss: 0.29919, val_acc: 0.94667\n",
      "Epoch [3230/10000], loss: 0.31318 acc: 0.90667 val_loss: 0.29885, val_acc: 0.94667\n",
      "Epoch [3240/10000], loss: 0.31284 acc: 0.90667 val_loss: 0.29851, val_acc: 0.94667\n",
      "Epoch [3250/10000], loss: 0.31251 acc: 0.90667 val_loss: 0.29816, val_acc: 0.94667\n",
      "Epoch [3260/10000], loss: 0.31217 acc: 0.90667 val_loss: 0.29782, val_acc: 0.94667\n",
      "Epoch [3270/10000], loss: 0.31183 acc: 0.90667 val_loss: 0.29748, val_acc: 0.94667\n",
      "Epoch [3280/10000], loss: 0.31150 acc: 0.90667 val_loss: 0.29715, val_acc: 0.94667\n",
      "Epoch [3290/10000], loss: 0.31117 acc: 0.90667 val_loss: 0.29681, val_acc: 0.94667\n",
      "Epoch [3300/10000], loss: 0.31084 acc: 0.90667 val_loss: 0.29647, val_acc: 0.94667\n",
      "Epoch [3310/10000], loss: 0.31051 acc: 0.90667 val_loss: 0.29614, val_acc: 0.94667\n",
      "Epoch [3320/10000], loss: 0.31018 acc: 0.90667 val_loss: 0.29581, val_acc: 0.94667\n",
      "Epoch [3330/10000], loss: 0.30985 acc: 0.90667 val_loss: 0.29548, val_acc: 0.94667\n",
      "Epoch [3340/10000], loss: 0.30953 acc: 0.90667 val_loss: 0.29515, val_acc: 0.94667\n",
      "Epoch [3350/10000], loss: 0.30920 acc: 0.90667 val_loss: 0.29482, val_acc: 0.94667\n",
      "Epoch [3360/10000], loss: 0.30888 acc: 0.90667 val_loss: 0.29449, val_acc: 0.94667\n",
      "Epoch [3370/10000], loss: 0.30856 acc: 0.90667 val_loss: 0.29416, val_acc: 0.94667\n",
      "Epoch [3380/10000], loss: 0.30824 acc: 0.90667 val_loss: 0.29384, val_acc: 0.94667\n",
      "Epoch [3390/10000], loss: 0.30792 acc: 0.90667 val_loss: 0.29351, val_acc: 0.94667\n",
      "Epoch [3400/10000], loss: 0.30760 acc: 0.90667 val_loss: 0.29319, val_acc: 0.94667\n",
      "Epoch [3410/10000], loss: 0.30728 acc: 0.90667 val_loss: 0.29287, val_acc: 0.94667\n",
      "Epoch [3420/10000], loss: 0.30696 acc: 0.90667 val_loss: 0.29255, val_acc: 0.94667\n",
      "Epoch [3430/10000], loss: 0.30665 acc: 0.90667 val_loss: 0.29223, val_acc: 0.94667\n",
      "Epoch [3440/10000], loss: 0.30634 acc: 0.90667 val_loss: 0.29191, val_acc: 0.94667\n",
      "Epoch [3450/10000], loss: 0.30602 acc: 0.90667 val_loss: 0.29159, val_acc: 0.94667\n",
      "Epoch [3460/10000], loss: 0.30571 acc: 0.90667 val_loss: 0.29128, val_acc: 0.94667\n",
      "Epoch [3470/10000], loss: 0.30540 acc: 0.90667 val_loss: 0.29096, val_acc: 0.94667\n",
      "Epoch [3480/10000], loss: 0.30509 acc: 0.90667 val_loss: 0.29065, val_acc: 0.94667\n",
      "Epoch [3490/10000], loss: 0.30479 acc: 0.90667 val_loss: 0.29034, val_acc: 0.94667\n",
      "Epoch [3500/10000], loss: 0.30448 acc: 0.90667 val_loss: 0.29003, val_acc: 0.94667\n",
      "Epoch [3510/10000], loss: 0.30417 acc: 0.90667 val_loss: 0.28972, val_acc: 0.94667\n",
      "Epoch [3520/10000], loss: 0.30387 acc: 0.90667 val_loss: 0.28941, val_acc: 0.94667\n",
      "Epoch [3530/10000], loss: 0.30357 acc: 0.90667 val_loss: 0.28910, val_acc: 0.94667\n",
      "Epoch [3540/10000], loss: 0.30327 acc: 0.90667 val_loss: 0.28879, val_acc: 0.94667\n",
      "Epoch [3550/10000], loss: 0.30297 acc: 0.90667 val_loss: 0.28849, val_acc: 0.94667\n",
      "Epoch [3560/10000], loss: 0.30267 acc: 0.90667 val_loss: 0.28818, val_acc: 0.94667\n",
      "Epoch [3570/10000], loss: 0.30237 acc: 0.90667 val_loss: 0.28788, val_acc: 0.94667\n",
      "Epoch [3580/10000], loss: 0.30207 acc: 0.90667 val_loss: 0.28758, val_acc: 0.94667\n",
      "Epoch [3590/10000], loss: 0.30177 acc: 0.90667 val_loss: 0.28728, val_acc: 0.94667\n",
      "Epoch [3600/10000], loss: 0.30148 acc: 0.90667 val_loss: 0.28698, val_acc: 0.94667\n",
      "Epoch [3610/10000], loss: 0.30119 acc: 0.90667 val_loss: 0.28668, val_acc: 0.94667\n",
      "Epoch [3620/10000], loss: 0.30089 acc: 0.90667 val_loss: 0.28638, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.30060 acc: 0.90667 val_loss: 0.28608, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.30031 acc: 0.90667 val_loss: 0.28579, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.30002 acc: 0.90667 val_loss: 0.28549, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.29973 acc: 0.90667 val_loss: 0.28520, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.29944 acc: 0.90667 val_loss: 0.28491, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.29916 acc: 0.90667 val_loss: 0.28462, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.29887 acc: 0.90667 val_loss: 0.28433, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.29859 acc: 0.90667 val_loss: 0.28404, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.29830 acc: 0.90667 val_loss: 0.28375, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.29802 acc: 0.90667 val_loss: 0.28346, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.29774 acc: 0.90667 val_loss: 0.28318, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.29746 acc: 0.90667 val_loss: 0.28289, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.29718 acc: 0.90667 val_loss: 0.28261, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.29690 acc: 0.90667 val_loss: 0.28232, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.29663 acc: 0.90667 val_loss: 0.28204, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.29635 acc: 0.90667 val_loss: 0.28176, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.29607 acc: 0.90667 val_loss: 0.28148, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.29580 acc: 0.90667 val_loss: 0.28120, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.29553 acc: 0.90667 val_loss: 0.28092, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.29525 acc: 0.90667 val_loss: 0.28064, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.29498 acc: 0.90667 val_loss: 0.28037, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.29471 acc: 0.90667 val_loss: 0.28009, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.29444 acc: 0.90667 val_loss: 0.27982, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.29418 acc: 0.90667 val_loss: 0.27954, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.29391 acc: 0.90667 val_loss: 0.27927, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.29364 acc: 0.90667 val_loss: 0.27900, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.29338 acc: 0.90667 val_loss: 0.27873, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.29311 acc: 0.90667 val_loss: 0.27846, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.29285 acc: 0.90667 val_loss: 0.27819, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.29258 acc: 0.90667 val_loss: 0.27792, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.29232 acc: 0.90667 val_loss: 0.27766, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.29206 acc: 0.90667 val_loss: 0.27739, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.29180 acc: 0.90667 val_loss: 0.27712, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.29154 acc: 0.90667 val_loss: 0.27686, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.29128 acc: 0.90667 val_loss: 0.27660, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.29103 acc: 0.90667 val_loss: 0.27633, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.29077 acc: 0.90667 val_loss: 0.27607, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.29052 acc: 0.90667 val_loss: 0.27581, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.29026 acc: 0.90667 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.29001 acc: 0.90667 val_loss: 0.27529, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.28975 acc: 0.90667 val_loss: 0.27504, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.28950 acc: 0.90667 val_loss: 0.27478, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.28925 acc: 0.90667 val_loss: 0.27452, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.28900 acc: 0.90667 val_loss: 0.27427, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.28875 acc: 0.90667 val_loss: 0.27401, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.28850 acc: 0.90667 val_loss: 0.27376, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.28826 acc: 0.90667 val_loss: 0.27351, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.28801 acc: 0.90667 val_loss: 0.27325, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.28776 acc: 0.90667 val_loss: 0.27300, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.28752 acc: 0.90667 val_loss: 0.27275, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.28727 acc: 0.90667 val_loss: 0.27250, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.28703 acc: 0.90667 val_loss: 0.27225, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.28679 acc: 0.90667 val_loss: 0.27200, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.28654 acc: 0.90667 val_loss: 0.27176, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.28630 acc: 0.90667 val_loss: 0.27151, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.28606 acc: 0.90667 val_loss: 0.27127, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.28582 acc: 0.90667 val_loss: 0.27102, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.28559 acc: 0.90667 val_loss: 0.27078, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.28535 acc: 0.90667 val_loss: 0.27053, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.28511 acc: 0.90667 val_loss: 0.27029, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.28487 acc: 0.90667 val_loss: 0.27005, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.28464 acc: 0.90667 val_loss: 0.26981, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.28440 acc: 0.90667 val_loss: 0.26957, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.28417 acc: 0.90667 val_loss: 0.26933, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.28394 acc: 0.90667 val_loss: 0.26909, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.28370 acc: 0.90667 val_loss: 0.26885, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.28347 acc: 0.90667 val_loss: 0.26862, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.28324 acc: 0.90667 val_loss: 0.26838, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.28301 acc: 0.90667 val_loss: 0.26815, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.28278 acc: 0.90667 val_loss: 0.26791, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.28255 acc: 0.90667 val_loss: 0.26768, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.28233 acc: 0.90667 val_loss: 0.26744, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.28210 acc: 0.90667 val_loss: 0.26721, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.28187 acc: 0.90667 val_loss: 0.26698, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.28165 acc: 0.90667 val_loss: 0.26675, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.28142 acc: 0.90667 val_loss: 0.26652, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.28120 acc: 0.90667 val_loss: 0.26629, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.28098 acc: 0.90667 val_loss: 0.26606, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.28075 acc: 0.90667 val_loss: 0.26583, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.28053 acc: 0.90667 val_loss: 0.26560, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.28031 acc: 0.90667 val_loss: 0.26538, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.28009 acc: 0.90667 val_loss: 0.26515, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.27987 acc: 0.90667 val_loss: 0.26493, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.27965 acc: 0.90667 val_loss: 0.26470, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.27943 acc: 0.90667 val_loss: 0.26448, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.27922 acc: 0.90667 val_loss: 0.26425, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.27900 acc: 0.90667 val_loss: 0.26403, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.27878 acc: 0.90667 val_loss: 0.26381, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.27857 acc: 0.90667 val_loss: 0.26359, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.27835 acc: 0.90667 val_loss: 0.26337, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.27814 acc: 0.90667 val_loss: 0.26315, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.27792 acc: 0.90667 val_loss: 0.26293, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.27771 acc: 0.90667 val_loss: 0.26271, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.27750 acc: 0.90667 val_loss: 0.26249, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.27729 acc: 0.90667 val_loss: 0.26228, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.27708 acc: 0.90667 val_loss: 0.26206, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.27687 acc: 0.90667 val_loss: 0.26185, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.27666 acc: 0.90667 val_loss: 0.26163, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.27645 acc: 0.90667 val_loss: 0.26142, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.27624 acc: 0.90667 val_loss: 0.26120, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.27603 acc: 0.90667 val_loss: 0.26099, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.27583 acc: 0.90667 val_loss: 0.26078, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.27562 acc: 0.90667 val_loss: 0.26057, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.27541 acc: 0.90667 val_loss: 0.26035, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.27521 acc: 0.90667 val_loss: 0.26014, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.27500 acc: 0.90667 val_loss: 0.25993, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.27480 acc: 0.90667 val_loss: 0.25973, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.27460 acc: 0.90667 val_loss: 0.25952, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.27440 acc: 0.90667 val_loss: 0.25931, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.27419 acc: 0.90667 val_loss: 0.25910, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.27399 acc: 0.90667 val_loss: 0.25889, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.27379 acc: 0.90667 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.27359 acc: 0.90667 val_loss: 0.25848, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.27339 acc: 0.90667 val_loss: 0.25828, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.27319 acc: 0.90667 val_loss: 0.25807, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.27300 acc: 0.90667 val_loss: 0.25787, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.27280 acc: 0.90667 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.27260 acc: 0.90667 val_loss: 0.25746, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.27241 acc: 0.90667 val_loss: 0.25726, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.27221 acc: 0.90667 val_loss: 0.25706, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.27202 acc: 0.90667 val_loss: 0.25686, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.27182 acc: 0.90667 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.27163 acc: 0.90667 val_loss: 0.25646, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.27143 acc: 0.90667 val_loss: 0.25626, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.27124 acc: 0.90667 val_loss: 0.25606, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.27105 acc: 0.90667 val_loss: 0.25587, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.27086 acc: 0.90667 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.27067 acc: 0.90667 val_loss: 0.25547, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.27048 acc: 0.90667 val_loss: 0.25528, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.27029 acc: 0.90667 val_loss: 0.25508, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.27010 acc: 0.90667 val_loss: 0.25489, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.26991 acc: 0.90667 val_loss: 0.25469, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.26972 acc: 0.90667 val_loss: 0.25450, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.26953 acc: 0.90667 val_loss: 0.25431, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.26935 acc: 0.90667 val_loss: 0.25411, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.26916 acc: 0.90667 val_loss: 0.25392, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.26897 acc: 0.90667 val_loss: 0.25373, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.26879 acc: 0.90667 val_loss: 0.25354, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.26860 acc: 0.90667 val_loss: 0.25335, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.26842 acc: 0.90667 val_loss: 0.25316, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.26824 acc: 0.90667 val_loss: 0.25297, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.26805 acc: 0.90667 val_loss: 0.25278, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.26787 acc: 0.90667 val_loss: 0.25259, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.26769 acc: 0.90667 val_loss: 0.25240, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.26751 acc: 0.90667 val_loss: 0.25222, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.26733 acc: 0.90667 val_loss: 0.25203, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.26715 acc: 0.90667 val_loss: 0.25184, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.26697 acc: 0.90667 val_loss: 0.25166, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.26679 acc: 0.90667 val_loss: 0.25147, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.26661 acc: 0.90667 val_loss: 0.25129, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.26643 acc: 0.90667 val_loss: 0.25111, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.26625 acc: 0.90667 val_loss: 0.25092, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.26608 acc: 0.90667 val_loss: 0.25074, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.26590 acc: 0.90667 val_loss: 0.25056, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.26572 acc: 0.90667 val_loss: 0.25037, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.26555 acc: 0.90667 val_loss: 0.25019, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.26537 acc: 0.90667 val_loss: 0.25001, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.26520 acc: 0.90667 val_loss: 0.24983, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.26502 acc: 0.90667 val_loss: 0.24965, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.26485 acc: 0.90667 val_loss: 0.24947, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.26468 acc: 0.90667 val_loss: 0.24929, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.26450 acc: 0.90667 val_loss: 0.24912, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.26433 acc: 0.90667 val_loss: 0.24894, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.26416 acc: 0.90667 val_loss: 0.24876, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.26399 acc: 0.90667 val_loss: 0.24858, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.26382 acc: 0.90667 val_loss: 0.24841, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.26365 acc: 0.90667 val_loss: 0.24823, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.26348 acc: 0.90667 val_loss: 0.24806, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.26331 acc: 0.90667 val_loss: 0.24788, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.26314 acc: 0.90667 val_loss: 0.24771, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.26297 acc: 0.90667 val_loss: 0.24753, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.26280 acc: 0.90667 val_loss: 0.24736, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.26264 acc: 0.90667 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.26247 acc: 0.90667 val_loss: 0.24701, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.26230 acc: 0.90667 val_loss: 0.24684, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.26214 acc: 0.90667 val_loss: 0.24667, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.26197 acc: 0.90667 val_loss: 0.24650, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.26181 acc: 0.90667 val_loss: 0.24633, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.26164 acc: 0.90667 val_loss: 0.24616, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.26148 acc: 0.90667 val_loss: 0.24599, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.26131 acc: 0.90667 val_loss: 0.24582, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.26115 acc: 0.90667 val_loss: 0.24565, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.26099 acc: 0.90667 val_loss: 0.24548, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.26083 acc: 0.90667 val_loss: 0.24531, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.26066 acc: 0.90667 val_loss: 0.24514, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.26050 acc: 0.90667 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.26034 acc: 0.90667 val_loss: 0.24481, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.26018 acc: 0.90667 val_loss: 0.24464, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.26002 acc: 0.90667 val_loss: 0.24448, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.25986 acc: 0.90667 val_loss: 0.24431, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.25970 acc: 0.90667 val_loss: 0.24415, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.25954 acc: 0.90667 val_loss: 0.24398, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.25939 acc: 0.90667 val_loss: 0.24382, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.25923 acc: 0.90667 val_loss: 0.24366, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.25907 acc: 0.90667 val_loss: 0.24349, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.25891 acc: 0.90667 val_loss: 0.24333, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.25876 acc: 0.90667 val_loss: 0.24317, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.25860 acc: 0.90667 val_loss: 0.24301, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.25845 acc: 0.90667 val_loss: 0.24285, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.25829 acc: 0.90667 val_loss: 0.24268, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.25814 acc: 0.90667 val_loss: 0.24252, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.25798 acc: 0.90667 val_loss: 0.24236, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.25783 acc: 0.90667 val_loss: 0.24220, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.25767 acc: 0.90667 val_loss: 0.24205, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.25752 acc: 0.90667 val_loss: 0.24189, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.25737 acc: 0.90667 val_loss: 0.24173, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.25722 acc: 0.90667 val_loss: 0.24157, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.25706 acc: 0.90667 val_loss: 0.24141, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.25691 acc: 0.90667 val_loss: 0.24126, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.25676 acc: 0.90667 val_loss: 0.24110, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.25661 acc: 0.90667 val_loss: 0.24094, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.25646 acc: 0.90667 val_loss: 0.24079, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.25631 acc: 0.90667 val_loss: 0.24063, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.25616 acc: 0.90667 val_loss: 0.24048, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.25601 acc: 0.90667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.25586 acc: 0.90667 val_loss: 0.24017, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.25571 acc: 0.90667 val_loss: 0.24001, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.25557 acc: 0.90667 val_loss: 0.23986, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.25542 acc: 0.90667 val_loss: 0.23971, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.25527 acc: 0.90667 val_loss: 0.23955, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.25513 acc: 0.90667 val_loss: 0.23940, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.25498 acc: 0.90667 val_loss: 0.23925, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.25483 acc: 0.90667 val_loss: 0.23910, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.25469 acc: 0.90667 val_loss: 0.23895, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.25454 acc: 0.90667 val_loss: 0.23879, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.25440 acc: 0.90667 val_loss: 0.23864, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.25425 acc: 0.90667 val_loss: 0.23849, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.25411 acc: 0.90667 val_loss: 0.23834, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.25397 acc: 0.90667 val_loss: 0.23819, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.25382 acc: 0.90667 val_loss: 0.23805, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.25368 acc: 0.90667 val_loss: 0.23790, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.25354 acc: 0.90667 val_loss: 0.23775, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.25340 acc: 0.90667 val_loss: 0.23760, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.25325 acc: 0.90667 val_loss: 0.23745, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.25311 acc: 0.90667 val_loss: 0.23731, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.25297 acc: 0.90667 val_loss: 0.23716, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.25283 acc: 0.90667 val_loss: 0.23701, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.25269 acc: 0.90667 val_loss: 0.23687, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.25255 acc: 0.90667 val_loss: 0.23672, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.25241 acc: 0.90667 val_loss: 0.23658, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.25227 acc: 0.90667 val_loss: 0.23643, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.25213 acc: 0.90667 val_loss: 0.23629, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.25199 acc: 0.90667 val_loss: 0.23614, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.25186 acc: 0.90667 val_loss: 0.23600, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.25172 acc: 0.90667 val_loss: 0.23586, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.25158 acc: 0.90667 val_loss: 0.23571, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.25144 acc: 0.90667 val_loss: 0.23557, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.25131 acc: 0.90667 val_loss: 0.23543, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.25117 acc: 0.90667 val_loss: 0.23529, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.25104 acc: 0.90667 val_loss: 0.23514, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.25090 acc: 0.90667 val_loss: 0.23500, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.25076 acc: 0.90667 val_loss: 0.23486, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.25063 acc: 0.90667 val_loss: 0.23472, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.25049 acc: 0.90667 val_loss: 0.23458, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.25036 acc: 0.90667 val_loss: 0.23444, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.25023 acc: 0.90667 val_loss: 0.23430, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.25009 acc: 0.90667 val_loss: 0.23416, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.24996 acc: 0.90667 val_loss: 0.23402, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.24983 acc: 0.90667 val_loss: 0.23388, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.24969 acc: 0.90667 val_loss: 0.23375, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.24956 acc: 0.90667 val_loss: 0.23361, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.24943 acc: 0.90667 val_loss: 0.23347, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.24930 acc: 0.90667 val_loss: 0.23333, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.24917 acc: 0.90667 val_loss: 0.23320, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.24904 acc: 0.90667 val_loss: 0.23306, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.24891 acc: 0.90667 val_loss: 0.23292, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.24878 acc: 0.90667 val_loss: 0.23279, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.24865 acc: 0.90667 val_loss: 0.23265, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.24852 acc: 0.90667 val_loss: 0.23252, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.24839 acc: 0.90667 val_loss: 0.23238, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.24826 acc: 0.90667 val_loss: 0.23225, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.24813 acc: 0.90667 val_loss: 0.23211, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.24800 acc: 0.90667 val_loss: 0.23198, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.24787 acc: 0.90667 val_loss: 0.23184, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.24775 acc: 0.90667 val_loss: 0.23171, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.24762 acc: 0.90667 val_loss: 0.23158, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.24749 acc: 0.90667 val_loss: 0.23145, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.24736 acc: 0.90667 val_loss: 0.23131, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.24724 acc: 0.90667 val_loss: 0.23118, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.24711 acc: 0.90667 val_loss: 0.23105, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.24699 acc: 0.90667 val_loss: 0.23092, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.24686 acc: 0.90667 val_loss: 0.23079, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.24674 acc: 0.90667 val_loss: 0.23066, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.24661 acc: 0.90667 val_loss: 0.23053, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.24649 acc: 0.90667 val_loss: 0.23040, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.24636 acc: 0.90667 val_loss: 0.23027, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.24624 acc: 0.90667 val_loss: 0.23014, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.24611 acc: 0.90667 val_loss: 0.23001, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.24599 acc: 0.90667 val_loss: 0.22988, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.24587 acc: 0.90667 val_loss: 0.22975, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.24575 acc: 0.90667 val_loss: 0.22962, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.24562 acc: 0.90667 val_loss: 0.22949, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.24550 acc: 0.90667 val_loss: 0.22936, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.24538 acc: 0.90667 val_loss: 0.22924, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.24526 acc: 0.90667 val_loss: 0.22911, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.24514 acc: 0.90667 val_loss: 0.22898, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.24502 acc: 0.90667 val_loss: 0.22886, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.24489 acc: 0.90667 val_loss: 0.22873, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.24477 acc: 0.90667 val_loss: 0.22860, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.24465 acc: 0.90667 val_loss: 0.22848, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.24453 acc: 0.90667 val_loss: 0.22835, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.24441 acc: 0.90667 val_loss: 0.22823, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.24430 acc: 0.90667 val_loss: 0.22810, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.24418 acc: 0.90667 val_loss: 0.22798, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.24406 acc: 0.90667 val_loss: 0.22785, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.24394 acc: 0.90667 val_loss: 0.22773, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.24382 acc: 0.90667 val_loss: 0.22761, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.24370 acc: 0.90667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.24359 acc: 0.90667 val_loss: 0.22736, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.24347 acc: 0.90667 val_loss: 0.22724, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.24335 acc: 0.90667 val_loss: 0.22711, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.24324 acc: 0.90667 val_loss: 0.22699, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.24312 acc: 0.90667 val_loss: 0.22687, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.24300 acc: 0.90667 val_loss: 0.22675, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.24289 acc: 0.90667 val_loss: 0.22663, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.24277 acc: 0.90667 val_loss: 0.22651, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.24266 acc: 0.90667 val_loss: 0.22638, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.24254 acc: 0.90667 val_loss: 0.22626, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.24243 acc: 0.90667 val_loss: 0.22614, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.24231 acc: 0.90667 val_loss: 0.22602, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.24220 acc: 0.90667 val_loss: 0.22590, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.24208 acc: 0.90667 val_loss: 0.22578, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.24197 acc: 0.90667 val_loss: 0.22566, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.24186 acc: 0.90667 val_loss: 0.22555, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.24174 acc: 0.90667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.24163 acc: 0.90667 val_loss: 0.22531, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.24152 acc: 0.90667 val_loss: 0.22519, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.24141 acc: 0.90667 val_loss: 0.22507, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.24129 acc: 0.90667 val_loss: 0.22495, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.24118 acc: 0.90667 val_loss: 0.22484, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.24107 acc: 0.90667 val_loss: 0.22472, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.24096 acc: 0.90667 val_loss: 0.22460, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.24085 acc: 0.90667 val_loss: 0.22449, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.24074 acc: 0.90667 val_loss: 0.22437, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.24063 acc: 0.90667 val_loss: 0.22425, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.24052 acc: 0.90667 val_loss: 0.22414, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.24041 acc: 0.90667 val_loss: 0.22402, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.24030 acc: 0.90667 val_loss: 0.22391, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.24019 acc: 0.90667 val_loss: 0.22379, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.24008 acc: 0.90667 val_loss: 0.22368, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.23997 acc: 0.90667 val_loss: 0.22356, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.23986 acc: 0.90667 val_loss: 0.22345, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.23975 acc: 0.90667 val_loss: 0.22333, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.23964 acc: 0.90667 val_loss: 0.22322, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.23953 acc: 0.90667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.23943 acc: 0.90667 val_loss: 0.22299, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.23932 acc: 0.90667 val_loss: 0.22288, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.23921 acc: 0.90667 val_loss: 0.22277, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.23910 acc: 0.90667 val_loss: 0.22265, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.23900 acc: 0.90667 val_loss: 0.22254, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.23889 acc: 0.90667 val_loss: 0.22243, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.23879 acc: 0.90667 val_loss: 0.22232, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.23868 acc: 0.90667 val_loss: 0.22221, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.23857 acc: 0.90667 val_loss: 0.22209, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.23847 acc: 0.90667 val_loss: 0.22198, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.23836 acc: 0.90667 val_loss: 0.22187, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.23826 acc: 0.90667 val_loss: 0.22176, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.23815 acc: 0.90667 val_loss: 0.22165, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.23805 acc: 0.90667 val_loss: 0.22154, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.23794 acc: 0.90667 val_loss: 0.22143, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.23784 acc: 0.90667 val_loss: 0.22132, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.23774 acc: 0.90667 val_loss: 0.22121, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.23763 acc: 0.90667 val_loss: 0.22110, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.23753 acc: 0.90667 val_loss: 0.22099, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.23742 acc: 0.90667 val_loss: 0.22088, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.23732 acc: 0.90667 val_loss: 0.22078, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.23722 acc: 0.90667 val_loss: 0.22067, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.23712 acc: 0.90667 val_loss: 0.22056, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.23701 acc: 0.90667 val_loss: 0.22045, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.23691 acc: 0.90667 val_loss: 0.22034, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.23681 acc: 0.90667 val_loss: 0.22024, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.23671 acc: 0.90667 val_loss: 0.22013, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.23661 acc: 0.90667 val_loss: 0.22002, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.23651 acc: 0.90667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.23640 acc: 0.90667 val_loss: 0.21981, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.23630 acc: 0.90667 val_loss: 0.21970, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.23620 acc: 0.90667 val_loss: 0.21960, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.23610 acc: 0.90667 val_loss: 0.21949, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.23600 acc: 0.90667 val_loss: 0.21939, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.23590 acc: 0.90667 val_loss: 0.21928, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.23580 acc: 0.90667 val_loss: 0.21918, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.23570 acc: 0.90667 val_loss: 0.21907, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.23560 acc: 0.90667 val_loss: 0.21897, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.23551 acc: 0.90667 val_loss: 0.21886, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.23541 acc: 0.90667 val_loss: 0.21876, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.23531 acc: 0.90667 val_loss: 0.21865, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.23521 acc: 0.90667 val_loss: 0.21855, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.23511 acc: 0.90667 val_loss: 0.21845, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.23501 acc: 0.90667 val_loss: 0.21834, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.23492 acc: 0.90667 val_loss: 0.21824, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.23482 acc: 0.90667 val_loss: 0.21814, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.23472 acc: 0.90667 val_loss: 0.21803, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.23462 acc: 0.90667 val_loss: 0.21793, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.23453 acc: 0.90667 val_loss: 0.21783, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.23443 acc: 0.90667 val_loss: 0.21773, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.23433 acc: 0.90667 val_loss: 0.21762, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.23424 acc: 0.90667 val_loss: 0.21752, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.23414 acc: 0.90667 val_loss: 0.21742, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.23405 acc: 0.90667 val_loss: 0.21732, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.23395 acc: 0.90667 val_loss: 0.21722, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.23385 acc: 0.90667 val_loss: 0.21712, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.23376 acc: 0.90667 val_loss: 0.21702, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.23366 acc: 0.90667 val_loss: 0.21692, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.23357 acc: 0.90667 val_loss: 0.21682, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.23348 acc: 0.90667 val_loss: 0.21672, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.23338 acc: 0.90667 val_loss: 0.21662, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.23329 acc: 0.90667 val_loss: 0.21652, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.23319 acc: 0.90667 val_loss: 0.21642, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.23310 acc: 0.90667 val_loss: 0.21632, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.23301 acc: 0.90667 val_loss: 0.21622, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.23291 acc: 0.90667 val_loss: 0.21612, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.23282 acc: 0.90667 val_loss: 0.21602, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.23273 acc: 0.90667 val_loss: 0.21592, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.23263 acc: 0.90667 val_loss: 0.21582, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.23254 acc: 0.90667 val_loss: 0.21573, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.23245 acc: 0.90667 val_loss: 0.21563, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.23236 acc: 0.90667 val_loss: 0.21553, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.23226 acc: 0.90667 val_loss: 0.21543, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.23217 acc: 0.90667 val_loss: 0.21534, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.23208 acc: 0.90667 val_loss: 0.21524, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.23199 acc: 0.90667 val_loss: 0.21514, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.23190 acc: 0.90667 val_loss: 0.21505, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.23181 acc: 0.90667 val_loss: 0.21495, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.23172 acc: 0.90667 val_loss: 0.21485, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.23162 acc: 0.90667 val_loss: 0.21476, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.23153 acc: 0.90667 val_loss: 0.21466, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.23144 acc: 0.90667 val_loss: 0.21457, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.23135 acc: 0.90667 val_loss: 0.21447, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.23126 acc: 0.90667 val_loss: 0.21437, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.23117 acc: 0.90667 val_loss: 0.21428, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.23108 acc: 0.90667 val_loss: 0.21418, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.23099 acc: 0.90667 val_loss: 0.21409, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.23091 acc: 0.90667 val_loss: 0.21400, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.23082 acc: 0.90667 val_loss: 0.21390, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.23073 acc: 0.90667 val_loss: 0.21381, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.23064 acc: 0.90667 val_loss: 0.21371, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.23055 acc: 0.90667 val_loss: 0.21362, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.23046 acc: 0.90667 val_loss: 0.21353, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.23037 acc: 0.90667 val_loss: 0.21343, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.23029 acc: 0.90667 val_loss: 0.21334, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.23020 acc: 0.90667 val_loss: 0.21325, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.23011 acc: 0.90667 val_loss: 0.21315, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.23002 acc: 0.90667 val_loss: 0.21306, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.22994 acc: 0.90667 val_loss: 0.21297, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.22985 acc: 0.90667 val_loss: 0.21288, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.22976 acc: 0.90667 val_loss: 0.21278, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.22968 acc: 0.90667 val_loss: 0.21269, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.22959 acc: 0.90667 val_loss: 0.21260, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.22950 acc: 0.90667 val_loss: 0.21251, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.22942 acc: 0.90667 val_loss: 0.21242, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.22933 acc: 0.90667 val_loss: 0.21233, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.22925 acc: 0.90667 val_loss: 0.21223, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.22916 acc: 0.90667 val_loss: 0.21214, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.22907 acc: 0.90667 val_loss: 0.21205, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.22899 acc: 0.90667 val_loss: 0.21196, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.22890 acc: 0.90667 val_loss: 0.21187, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.22882 acc: 0.90667 val_loss: 0.21178, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.22873 acc: 0.90667 val_loss: 0.21169, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.22865 acc: 0.90667 val_loss: 0.21160, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.22857 acc: 0.90667 val_loss: 0.21151, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.22848 acc: 0.90667 val_loss: 0.21142, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.22840 acc: 0.90667 val_loss: 0.21133, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.22831 acc: 0.90667 val_loss: 0.21124, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.22823 acc: 0.90667 val_loss: 0.21115, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.22815 acc: 0.90667 val_loss: 0.21107, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.22806 acc: 0.90667 val_loss: 0.21098, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.22798 acc: 0.90667 val_loss: 0.21089, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.22790 acc: 0.90667 val_loss: 0.21080, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.22781 acc: 0.90667 val_loss: 0.21071, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.22773 acc: 0.90667 val_loss: 0.21062, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.22765 acc: 0.90667 val_loss: 0.21054, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.22757 acc: 0.90667 val_loss: 0.21045, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.22748 acc: 0.90667 val_loss: 0.21036, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.22740 acc: 0.90667 val_loss: 0.21027, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.22732 acc: 0.90667 val_loss: 0.21019, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.22724 acc: 0.90667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.22716 acc: 0.90667 val_loss: 0.21001, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.22708 acc: 0.90667 val_loss: 0.20993, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.22699 acc: 0.90667 val_loss: 0.20984, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.22691 acc: 0.90667 val_loss: 0.20975, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.22683 acc: 0.90667 val_loss: 0.20967, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.22675 acc: 0.90667 val_loss: 0.20958, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.22667 acc: 0.90667 val_loss: 0.20949, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.22659 acc: 0.90667 val_loss: 0.20941, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.22651 acc: 0.90667 val_loss: 0.20932, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.22643 acc: 0.90667 val_loss: 0.20924, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.22635 acc: 0.90667 val_loss: 0.20915, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.22627 acc: 0.90667 val_loss: 0.20907, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.22619 acc: 0.90667 val_loss: 0.20898, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.22611 acc: 0.90667 val_loss: 0.20890, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.22603 acc: 0.90667 val_loss: 0.20881, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.22595 acc: 0.90667 val_loss: 0.20873, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.22587 acc: 0.90667 val_loss: 0.20865, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.22579 acc: 0.90667 val_loss: 0.20856, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.22572 acc: 0.90667 val_loss: 0.20848, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.22564 acc: 0.90667 val_loss: 0.20839, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.22556 acc: 0.90667 val_loss: 0.20831, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.22548 acc: 0.90667 val_loss: 0.20823, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.22540 acc: 0.90667 val_loss: 0.20814, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.22532 acc: 0.90667 val_loss: 0.20806, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.22525 acc: 0.90667 val_loss: 0.20798, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.22517 acc: 0.90667 val_loss: 0.20789, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.22509 acc: 0.90667 val_loss: 0.20781, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.22501 acc: 0.90667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.22494 acc: 0.90667 val_loss: 0.20765, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.22486 acc: 0.90667 val_loss: 0.20756, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.22478 acc: 0.90667 val_loss: 0.20748, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.22471 acc: 0.90667 val_loss: 0.20740, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.22463 acc: 0.90667 val_loss: 0.20732, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.22455 acc: 0.90667 val_loss: 0.20724, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.22448 acc: 0.90667 val_loss: 0.20716, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.22440 acc: 0.90667 val_loss: 0.20707, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.22432 acc: 0.90667 val_loss: 0.20699, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.22425 acc: 0.90667 val_loss: 0.20691, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.22417 acc: 0.90667 val_loss: 0.20683, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.22410 acc: 0.90667 val_loss: 0.20675, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.22402 acc: 0.90667 val_loss: 0.20667, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.22395 acc: 0.90667 val_loss: 0.20659, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.22387 acc: 0.90667 val_loss: 0.20651, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.22380 acc: 0.90667 val_loss: 0.20643, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.22372 acc: 0.90667 val_loss: 0.20635, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.22365 acc: 0.90667 val_loss: 0.20627, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.22357 acc: 0.90667 val_loss: 0.20619, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.22350 acc: 0.90667 val_loss: 0.20611, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.22342 acc: 0.90667 val_loss: 0.20603, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.22335 acc: 0.90667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.22327 acc: 0.90667 val_loss: 0.20587, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.22320 acc: 0.90667 val_loss: 0.20579, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.22313 acc: 0.90667 val_loss: 0.20571, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.22305 acc: 0.90667 val_loss: 0.20563, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.22298 acc: 0.90667 val_loss: 0.20556, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.22291 acc: 0.90667 val_loss: 0.20548, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.22283 acc: 0.90667 val_loss: 0.20540, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.22276 acc: 0.90667 val_loss: 0.20532, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.22269 acc: 0.90667 val_loss: 0.20524, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.22261 acc: 0.90667 val_loss: 0.20517, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.22254 acc: 0.90667 val_loss: 0.20509, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.22247 acc: 0.90667 val_loss: 0.20501, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.22240 acc: 0.90667 val_loss: 0.20493, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.22232 acc: 0.90667 val_loss: 0.20485, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.22225 acc: 0.90667 val_loss: 0.20478, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.22218 acc: 0.90667 val_loss: 0.20470, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.22211 acc: 0.90667 val_loss: 0.20462, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.22204 acc: 0.90667 val_loss: 0.20455, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.22196 acc: 0.90667 val_loss: 0.20447, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.22189 acc: 0.90667 val_loss: 0.20439, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.22182 acc: 0.90667 val_loss: 0.20432, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.22175 acc: 0.90667 val_loss: 0.20424, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.22168 acc: 0.90667 val_loss: 0.20416, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.22161 acc: 0.90667 val_loss: 0.20409, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.22154 acc: 0.90667 val_loss: 0.20401, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.22147 acc: 0.90667 val_loss: 0.20394, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.22140 acc: 0.90667 val_loss: 0.20386, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.22133 acc: 0.90667 val_loss: 0.20379, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.22126 acc: 0.90667 val_loss: 0.20371, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.22118 acc: 0.90667 val_loss: 0.20364, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.22111 acc: 0.90667 val_loss: 0.20356, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.22105 acc: 0.90667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.22098 acc: 0.90667 val_loss: 0.20341, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.22091 acc: 0.90667 val_loss: 0.20334, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.22084 acc: 0.90667 val_loss: 0.20326, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.22077 acc: 0.90667 val_loss: 0.20319, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.22070 acc: 0.90667 val_loss: 0.20311, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.22063 acc: 0.90667 val_loss: 0.20304, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.22056 acc: 0.90667 val_loss: 0.20296, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.22049 acc: 0.90667 val_loss: 0.20289, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.22042 acc: 0.90667 val_loss: 0.20282, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.22035 acc: 0.90667 val_loss: 0.20274, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.22028 acc: 0.90667 val_loss: 0.20267, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.22022 acc: 0.90667 val_loss: 0.20260, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.22015 acc: 0.90667 val_loss: 0.20252, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.22008 acc: 0.90667 val_loss: 0.20245, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.22001 acc: 0.90667 val_loss: 0.20238, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.21994 acc: 0.90667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.21988 acc: 0.90667 val_loss: 0.20223, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.21981 acc: 0.90667 val_loss: 0.20216, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.21974 acc: 0.90667 val_loss: 0.20209, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.21967 acc: 0.90667 val_loss: 0.20201, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.21961 acc: 0.90667 val_loss: 0.20194, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.21954 acc: 0.90667 val_loss: 0.20187, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.21947 acc: 0.90667 val_loss: 0.20180, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.21940 acc: 0.90667 val_loss: 0.20173, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.21934 acc: 0.90667 val_loss: 0.20165, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.21927 acc: 0.90667 val_loss: 0.20158, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.21920 acc: 0.90667 val_loss: 0.20151, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.21914 acc: 0.90667 val_loss: 0.20144, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.21907 acc: 0.90667 val_loss: 0.20137, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.21901 acc: 0.90667 val_loss: 0.20130, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.21894 acc: 0.90667 val_loss: 0.20123, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.21887 acc: 0.90667 val_loss: 0.20115, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.21881 acc: 0.90667 val_loss: 0.20108, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.21874 acc: 0.90667 val_loss: 0.20101, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.21868 acc: 0.90667 val_loss: 0.20094, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.21861 acc: 0.90667 val_loss: 0.20087, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.21854 acc: 0.90667 val_loss: 0.20080, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.21848 acc: 0.90667 val_loss: 0.20073, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.21841 acc: 0.90667 val_loss: 0.20066, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.21835 acc: 0.90667 val_loss: 0.20059, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.21828 acc: 0.90667 val_loss: 0.20052, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.21822 acc: 0.90667 val_loss: 0.20045, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.21815 acc: 0.90667 val_loss: 0.20038, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.21809 acc: 0.90667 val_loss: 0.20031, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.21803 acc: 0.90667 val_loss: 0.20024, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.21796 acc: 0.90667 val_loss: 0.20017, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.21790 acc: 0.90667 val_loss: 0.20010, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.21783 acc: 0.90667 val_loss: 0.20004, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.21777 acc: 0.90667 val_loss: 0.19997, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.21770 acc: 0.90667 val_loss: 0.19990, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.21764 acc: 0.90667 val_loss: 0.19983, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.21758 acc: 0.90667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.21751 acc: 0.90667 val_loss: 0.19969, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.21745 acc: 0.90667 val_loss: 0.19962, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.21739 acc: 0.90667 val_loss: 0.19956, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.21732 acc: 0.90667 val_loss: 0.19949, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.21726 acc: 0.90667 val_loss: 0.19942, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.21720 acc: 0.90667 val_loss: 0.19935, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.21713 acc: 0.90667 val_loss: 0.19928, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.21707 acc: 0.90667 val_loss: 0.19922, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.21701 acc: 0.90667 val_loss: 0.19915, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.21695 acc: 0.90667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.21688 acc: 0.90667 val_loss: 0.19901, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.21682 acc: 0.90667 val_loss: 0.19895, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.21676 acc: 0.90667 val_loss: 0.19888, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.21670 acc: 0.90667 val_loss: 0.19881, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.21663 acc: 0.90667 val_loss: 0.19874, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.21657 acc: 0.90667 val_loss: 0.19868, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.21651 acc: 0.90667 val_loss: 0.19861, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.21645 acc: 0.90667 val_loss: 0.19854, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.21639 acc: 0.90667 val_loss: 0.19848, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.21633 acc: 0.90667 val_loss: 0.19841, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.21626 acc: 0.90667 val_loss: 0.19835, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.21620 acc: 0.90667 val_loss: 0.19828, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.21614 acc: 0.90667 val_loss: 0.19821, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.21608 acc: 0.90667 val_loss: 0.19815, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.21602 acc: 0.90667 val_loss: 0.19808, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.21596 acc: 0.90667 val_loss: 0.19802, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.21590 acc: 0.90667 val_loss: 0.19795, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "# 繰り返し計算メインループ\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 訓練フェーズ\n",
    "    \n",
    "    #勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 予測計算\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # 損失計算\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 勾配計算\n",
    "    loss.backward()\n",
    "    \n",
    "    # パラメータ修正\n",
    "    optimizer.step()\n",
    "\n",
    "    # 予測ラベル算出\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 損失と精度の計算\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    #予測フェーズ\n",
    "\n",
    "    # 予測計算\n",
    "    outputs_test = net(inputs_test)\n",
    "\n",
    "    # 損失計算\n",
    "    loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "    # 予測ラベル算出\n",
    "    predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "    # 損失と精度の計算\n",
    "    val_loss =  loss_test.item()\n",
    "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ((epoch) % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOztcpv3B8wS"
   },
   "source": [
    "## 7.11 結果確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Q5EZQ946B8wS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態: 損失: 1.09263 精度: 0.26667\n",
      "最終状態: 損失: 0.19795 精度: 0.96000\n"
     ]
    }
   ],
   "source": [
    "#損失と精度の確認\n",
    "\n",
    "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
    "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LbibwG3bB8wS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の表示 (損失)\n",
    "\n",
    "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
    "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
    "plt.xlabel('繰り返し回数')\n",
    "plt.ylabel('損失')\n",
    "plt.title('学習曲線(損失)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WJnWmovUB8wS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の表示 (精度)\n",
    "\n",
    "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
    "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
    "plt.xlabel('繰り返し回数')\n",
    "plt.ylabel('精度')\n",
    "plt.title('学習曲線(精度)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JG3V10NNB8wT"
   },
   "source": [
    "### モデルへの入力と出力の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "vWjT02ChB8wT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "# 正解データの0番目、2番目、3番目\n",
    "\n",
    "print(labels[[0,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "2j8v5mnCB8wT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3 4.7]\n",
      " [5.  1.6]\n",
      " [6.4 5.6]]\n"
     ]
    }
   ],
   "source": [
    "# 該当する入力値を抽出\n",
    "\n",
    "i3 = inputs[[0,2,3],:]\n",
    "print(i3.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "9skIo4OwB8wT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.8071 14.1937 12.9986]\n",
      " [12.8262  9.8     0.1734]\n",
      " [ 6.7954 15.0928 17.1111]]\n",
      "[[0.0035 0.765  0.2315]\n",
      " [0.9537 0.0463 0.    ]\n",
      " [0.     0.1173 0.8827]]\n"
     ]
    }
   ],
   "source": [
    "# 出力値にsoftmax関数をかけた結果を取得\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1) # 行単位でsoftmaxをかけてくれる\n",
    "o3 = net(i3)\n",
    "k3 = softmax(o3)\n",
    "print(o3.data.numpy())\n",
    "print(k3.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([14.1937, 12.8262, 17.1111], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7650, 0.9537, 0.8827], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 2]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(o3, 1))\n",
    "print(torch.max(k3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPlEVs83B8wT"
   },
   "source": [
    "### 最終的な重み行列とバイアスの値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "rA6qeTWHB8wU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0452, -2.5735],\n",
      "        [ 1.3573,  0.8481],\n",
      "        [-1.4026,  4.7253]])\n",
      "tensor([ 1.7178,  1.6563, -0.3741])\n"
     ]
    }
   ],
   "source": [
    "# 重み行列\n",
    "print(net.l1.weight.data)\n",
    "\n",
    "# バイアス\n",
    "print(net.l1.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定境界の描画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 描画領域計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.6000, 7.6000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# x, yの描画領域計算\n",
    "x_min = x_train[:,0].min()\n",
    "x_max = x_train[:,0].max()\n",
    "y_min = x_train[:,1].min()\n",
    "y_max = x_train[:,1].max()\n",
    "x_bound = torch.tensor([x_min, x_max])\n",
    "\n",
    "# 結果確認\n",
    "print(x_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定境界用の１次関数定義\n",
    "def d_bound(x, i, W, B):\n",
    "    W1 = W[[2,0,1],:]\n",
    "    W2 = W - W1\n",
    "    w = W2[i,:]\n",
    "    B1 = B[[2,0,1]]\n",
    "    B2 = B - B1\n",
    "    b = B2[i]\n",
    "    v = -1/w[1]*(w[0]*x + b)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0898, 4.9179], dtype=torch.float64)\n",
      "tensor([2.2871, 3.7670], dtype=torch.float64)\n",
      "tensor([3.7981, 5.9337], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 決定境界のyの値を計算\n",
    "\n",
    "W = net.l1.weight.data\n",
    "B = net.l1.bias.data\n",
    "\n",
    "y0_bound = d_bound(x_bound, 0, W, B)\n",
    "y1_bound = d_bound(x_bound, 1, W, B)\n",
    "y2_bound = d_bound(x_bound, 2, W, B)\n",
    "\n",
    "# 結果確認\n",
    "print(y0_bound)\n",
    "print(y1_bound)\n",
    "print(y2_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0452, -2.5735],\n",
      "        [ 1.3573,  0.8481],\n",
      "        [-1.4026,  4.7253]])\n",
      "tensor([[-1.4026,  4.7253],\n",
      "        [ 3.0452, -2.5735],\n",
      "        [ 1.3573,  0.8481]])\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(W[[2,0,1],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 散布図と決定境界の標示\n",
    "\n",
    "# xとyの範囲を明示的に指定\n",
    "plt.axis([x_min, x_max, y_min, y_max])\n",
    "\n",
    "# 散布図\n",
    "plt.scatter(x_t0[:,0], x_t0[:,1], marker='x', c='k', s=50, label='0 (setosa)')\n",
    "plt.scatter(x_t1[:,0], x_t1[:,1], marker='o', c='b', s=50, label='1 (versicolour)')\n",
    "plt.scatter(x_t2[:,0], x_t2[:,1], marker='+', c='k', s=50, label='2 (virginica)')\n",
    "\n",
    "# 決定境界\n",
    "plt.plot(x_bound, y0_bound, label='2_0')\n",
    "plt.plot(x_bound, y1_bound, linestyle=':',label='0_1')\n",
    "plt.plot(x_bound, y2_bound,linestyle='-.',label='1_2')\n",
    "\n",
    "# 軸ラベルと凡例\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('petal_length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m016TNL9B8wU"
   },
   "source": [
    "## 7.12 入力変数の4次元化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "HI61G1-GB8wU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 4) (75, 4) (75,) (75,)\n"
     ]
    }
   ],
   "source": [
    "# 訓練データ、検証データに分割 (シャフルも同時に実施)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_org, y_org, train_size=75, test_size=75, \n",
    "    random_state=123)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# 入力次元数\n",
    "n_input = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ziivFupuB8wU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力データ(x)\n",
      "[[6.3 3.3 4.7 1.6]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.  3.  1.6 0.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.3 2.5 5.  1.9]]\n",
      "入力次元数: 4\n"
     ]
    }
   ],
   "source": [
    "print('入力データ(x)')\n",
    "print(x_train[:5,:])\n",
    "print(f'入力次元数: {n_input}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "SFZ-B_yyB8wU"
   },
   "outputs": [],
   "source": [
    "# 入力データ x_train と正解データ y_train のテンソル変数化\n",
    "inputs = torch.tensor(x_train).float()\n",
    "labels = torch.tensor(y_train).long()\n",
    "\n",
    "# 検証用データのテンソル変数化\n",
    "inputs_test = torch.tensor(x_test).float()\n",
    "labels_test = torch.tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "DORSG_Q2B8wU"
   },
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 初期化\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 損失関数： 交差エントロピー関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最適化アルゴリズム: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 繰り返し回数\n",
    "num_epochs = 10000\n",
    "\n",
    "# 評価結果記録用\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Y4gM9OQgB8wV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
      "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
      "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
      "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
      "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
      "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
      "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
      "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
      "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
      "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
      "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
      "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
      "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
      "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
      "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
      "Epoch [180/10000], loss: 0.62081 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
      "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
      "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
      "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
      "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
      "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
      "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
      "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
      "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
      "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
      "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
      "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
      "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
      "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
      "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
      "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
      "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
      "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
      "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
      "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
      "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
      "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
      "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
      "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
      "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
      "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
      "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
      "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
      "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
      "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
      "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
      "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
      "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
      "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44951, val_acc: 0.90667\n",
      "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
      "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
      "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
      "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
      "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
      "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
      "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
      "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
      "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
      "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
      "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
      "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
      "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
      "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
      "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
      "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
      "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
      "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
      "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
      "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
      "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
      "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
      "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
      "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
      "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
      "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
      "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
      "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
      "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
      "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
      "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
      "Epoch [830/10000], loss: 0.39646 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
      "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
      "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
      "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
      "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
      "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
      "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
      "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
      "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
      "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
      "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
      "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
      "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
      "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
      "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
      "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
      "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
      "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
      "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
      "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35758, val_acc: 0.96000\n",
      "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
      "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35505, val_acc: 0.96000\n",
      "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n",
      "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
      "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
      "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
      "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
      "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
      "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
      "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
      "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
      "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
      "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
      "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
      "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n",
      "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
      "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
      "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
      "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
      "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
      "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
      "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
      "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
      "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
      "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
      "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
      "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
      "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
      "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
      "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
      "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
      "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
      "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
      "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
      "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
      "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31853, val_acc: 0.96000\n",
      "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
      "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
      "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
      "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31490, val_acc: 0.96000\n",
      "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
      "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
      "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
      "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
      "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
      "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
      "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
      "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
      "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
      "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
      "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
      "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
      "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
      "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
      "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
      "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
      "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
      "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
      "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
      "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
      "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
      "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
      "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
      "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
      "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
      "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
      "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
      "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
      "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
      "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
      "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
      "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
      "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
      "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
      "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
      "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
      "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
      "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
      "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
      "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
      "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
      "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
      "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
      "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
      "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
      "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
      "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
      "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
      "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
      "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
      "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
      "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
      "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
      "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
      "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
      "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
      "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
      "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
      "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
      "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
      "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
      "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
      "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
      "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
      "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
      "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
      "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
      "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
      "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
      "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
      "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
      "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
      "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n",
      "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
      "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n",
      "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
      "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
      "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
      "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
      "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
      "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25921, val_acc: 0.96000\n",
      "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
      "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
      "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
      "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
      "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
      "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
      "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
      "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
      "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
      "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
      "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
      "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
      "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
      "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
      "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
      "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
      "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
      "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
      "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
      "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
      "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
      "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
      "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
      "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
      "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
      "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
      "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
      "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
      "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
      "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
      "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
      "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
      "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
      "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
      "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
      "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
      "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
      "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
      "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
      "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
      "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
      "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
      "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
      "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
      "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
      "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
      "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
      "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
      "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
      "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
      "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
      "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
      "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23287, val_acc: 0.96000\n",
      "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
      "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
      "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
      "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
      "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
      "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
      "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
      "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
      "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
      "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
      "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
      "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
      "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
      "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
      "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
      "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
      "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
      "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
      "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22577, val_acc: 0.96000\n",
      "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
      "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
      "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
      "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
      "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
      "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
      "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
      "Epoch [3140/10000], loss: 0.22358 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
      "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
      "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
      "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
      "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
      "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
      "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
      "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
      "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
      "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
      "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
      "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
      "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
      "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
      "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
      "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
      "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
      "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
      "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
      "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
      "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
      "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
      "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n",
      "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
      "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21483, val_acc: 0.96000\n",
      "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
      "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
      "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21396, val_acc: 0.96000\n",
      "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
      "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n",
      "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
      "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
      "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
      "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
      "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
      "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
      "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
      "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
      "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
      "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
      "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
      "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
      "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
      "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
      "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
      "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
      "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.18622 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18762, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18479, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18395, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.17229 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17589, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16939, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.16094 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15998, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.15215 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.14627 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15314, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15080, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14266, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 訓練フェーズ\n",
    "    \n",
    "    #勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 予測計算\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # 損失計算\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 勾配計算\n",
    "    loss.backward()\n",
    "    \n",
    "    # パラメータ修正\n",
    "    optimizer.step()\n",
    "\n",
    "    #予測値算出\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 損失と精度の計算\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    #予測フェーズ\n",
    "\n",
    "    # 予測計算\n",
    "    outputs_test = net(inputs_test)\n",
    "\n",
    "    # 損失計算\n",
    "    loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "    # 予測ラベル算出\n",
    "    predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "    # 損失と精度の計算\n",
    "    val_loss =  loss_test.item()\n",
    "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( epoch % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "EGnDSJReB8wV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態: 損失: 1.09158 精度: 0.26667\n",
      "最終状態: 損失: 0.13724 精度: 0.96000\n"
     ]
    }
   ],
   "source": [
    "# 損失と精度の確認\n",
    "\n",
    "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
    "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "z4NJkJDJB8wV"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の表示 (損失)\n",
    "\n",
    "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
    "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
    "plt.xlabel('繰り返し回数')\n",
    "plt.ylabel('損失')\n",
    "plt.title('学習曲線(損失)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "jZPEkfLJB8wW"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の表示 (精度)\n",
    "\n",
    "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
    "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
    "plt.xlabel('繰り返し回数')\n",
    "plt.ylabel('精度')\n",
    "plt.title('学習曲線(精度)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwXP0yeKB8wK"
   },
   "source": [
    "## コラム NLLLoss損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Lg7-oAJ4B8wL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([0, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "# 入力変数の準備\n",
    "\n",
    "# 擬似的な出力データ\n",
    "outputs_np = np.array(range(1, 13)).reshape((4,3))\n",
    "# 擬似的な正解データ\n",
    "labels_np = np.array([0, 1, 2, 0])\n",
    "\n",
    "# Tensor化\n",
    "outputs_dummy = torch.tensor(outputs_np).float()\n",
    "labels_dummy = torch.tensor(labels_np).long()\n",
    "\n",
    "# 結果確認\n",
    "print(outputs_dummy.data)\n",
    "print(labels_dummy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "mf68l_reB8wL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.25\n"
     ]
    }
   ],
   "source": [
    "# NLLLoss関数の呼び出し\n",
    "\n",
    "nllloss = nn.NLLLoss()\n",
    "loss = nllloss(outputs_dummy, labels_dummy)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyX9w-MPB8wW"
   },
   "source": [
    "## コラム 多値分類モデルの他の実装パターン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYdZPF06B8wW"
   },
   "source": [
    "### パターン2 モデルクラス側にLogS1oftmax関数を含める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Cgth7H98B8wW"
   },
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "# 2入力3出力のロジスティック回帰モデル\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_output)\n",
    "        # softmax関数の定義\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "                \n",
    "        # 初期値を全部1にする\n",
    "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
    "        self.l1.weight.data.fill_(1.0)\n",
    "        self.l1.bias.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)         \n",
    "        x2 = self.logsoftmax(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "ZuL4yILWGMzZ"
   },
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 初期化\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 損失関数： NLLLoss関数\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 最適化関数: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "3uyUhRWLFjt5"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"216pt\" height=\"391pt\"\n viewBox=\"0.00 0.00 216.00 391.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 387)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-387 212,-387 212,4 -4,4\"/>\n<!-- 139634868155152 -->\n<g id=\"node1\" class=\"node\">\n<title>139634868155152</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"130.5,-31 76.5,-31 76.5,0 130.5,0 130.5,-31\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 139634869783760 -->\n<g id=\"node2\" class=\"node\">\n<title>139634869783760</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-86 47,-86 47,-67 160,-67 160,-86\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">NllLossBackward0</text>\n</g>\n<!-- 139634869783760&#45;&gt;139634868155152 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139634869783760&#45;&gt;139634868155152</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-66.79C103.5,-60.07 103.5,-50.4 103.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-41.19 103.5,-31.19 100,-41.19 107,-41.19\"/>\n</g>\n<!-- 139634870186480 -->\n<g id=\"node3\" class=\"node\">\n<title>139634870186480</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"169,-141 38,-141 38,-122 169,-122 169,-141\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">LogSoftmaxBackward0</text>\n</g>\n<!-- 139634870186480&#45;&gt;139634869783760 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139634870186480&#45;&gt;139634869783760</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-121.75C103.5,-114.8 103.5,-104.85 103.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-96.09 103.5,-86.09 100,-96.09 107,-96.09\"/>\n</g>\n<!-- 139634869446928 -->\n<g id=\"node4\" class=\"node\">\n<title>139634869446928</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-196 53,-196 53,-177 154,-177 154,-196\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 139634869446928&#45;&gt;139634870186480 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139634869446928&#45;&gt;139634870186480</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-176.75C103.5,-169.8 103.5,-159.85 103.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-151.09 103.5,-141.09 100,-151.09 107,-151.09\"/>\n</g>\n<!-- 139634870122816 -->\n<g id=\"node5\" class=\"node\">\n<title>139634870122816</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139634870122816&#45;&gt;139634869446928 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139634870122816&#45;&gt;139634869446928</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.25,-231.75C66.97,-224.03 78.4,-212.6 87.72,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90.31,-205.64 94.91,-196.09 85.36,-200.69 90.31,-205.64\"/>\n</g>\n<!-- 139634867904320 -->\n<g id=\"node6\" class=\"node\">\n<title>139634867904320</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-317 21,-317 21,-287 80,-287 80,-317\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\">l1.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 139634867904320&#45;&gt;139634870122816 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139634867904320&#45;&gt;139634870122816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.84C50.5,-279.21 50.5,-269.7 50.5,-261.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.27 50.5,-251.27 47,-261.27 54,-261.27\"/>\n</g>\n<!-- 139635147514016 -->\n<g id=\"node7\" class=\"node\">\n<title>139635147514016</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-251 119,-251 119,-232 196,-232 196,-251\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 139635147514016&#45;&gt;139634869446928 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139635147514016&#45;&gt;139634869446928</title>\n<path fill=\"none\" stroke=\"black\" d=\"M148.58,-231.75C140.72,-224.03 129.07,-212.6 119.58,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121.84,-200.6 112.25,-196.09 116.94,-205.59 121.84,-200.6\"/>\n</g>\n<!-- 139634868924320 -->\n<g id=\"node8\" class=\"node\">\n<title>139634868924320</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-311.5 107,-311.5 107,-292.5 208,-292.5 208,-311.5\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-299.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139634868924320&#45;&gt;139635147514016 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139634868924320&#45;&gt;139635147514016</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.5,-292.37C157.5,-284.25 157.5,-271.81 157.5,-261.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161,-261.17 157.5,-251.17 154,-261.17 161,-261.17\"/>\n</g>\n<!-- 139634868415520 -->\n<g id=\"node9\" class=\"node\">\n<title>139634868415520</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"193,-383 122,-383 122,-353 193,-353 193,-383\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">l1.weight</text>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\"> (3, 4)</text>\n</g>\n<!-- 139634868415520&#45;&gt;139634868924320 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139634868415520&#45;&gt;139634868924320</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.5,-352.8C157.5,-343.7 157.5,-331.79 157.5,-321.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161,-321.84 157.5,-311.84 154,-321.84 161,-321.84\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7eff46b74550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 予測計算\n",
    "outputs = net(inputs)\n",
    "\n",
    "#  損失計算\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# 損失の計算グラフ可視化\n",
    "g = make_dot(loss, params=dict(net.named_parameters()))\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "pU9rqn5NB8wW"
   },
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 初期化\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 損失関数： NLLLoss関数\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 最適化関数: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 繰り返し回数\n",
    "num_epochs = 10000\n",
    "\n",
    "# 評価結果記録用\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "BsTrCuQ_B8wW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
      "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
      "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
      "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
      "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
      "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
      "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
      "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
      "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
      "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
      "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
      "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
      "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
      "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
      "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
      "Epoch [180/10000], loss: 0.62081 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
      "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
      "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
      "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
      "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
      "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
      "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
      "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
      "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
      "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
      "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
      "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
      "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
      "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
      "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
      "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
      "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
      "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
      "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
      "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
      "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
      "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
      "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
      "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
      "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
      "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
      "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
      "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
      "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
      "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
      "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
      "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
      "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
      "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44951, val_acc: 0.90667\n",
      "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
      "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
      "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
      "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
      "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
      "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
      "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
      "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
      "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
      "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
      "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
      "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
      "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
      "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
      "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
      "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
      "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
      "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
      "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
      "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
      "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
      "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
      "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
      "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
      "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
      "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
      "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
      "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
      "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
      "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
      "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
      "Epoch [830/10000], loss: 0.39646 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
      "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
      "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
      "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
      "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
      "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
      "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
      "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
      "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
      "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
      "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
      "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
      "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
      "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
      "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
      "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
      "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
      "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
      "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
      "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35758, val_acc: 0.96000\n",
      "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
      "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35505, val_acc: 0.96000\n",
      "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n",
      "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
      "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
      "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
      "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
      "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
      "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
      "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
      "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
      "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
      "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
      "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
      "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n",
      "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
      "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
      "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
      "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
      "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
      "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
      "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
      "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
      "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
      "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
      "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
      "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
      "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
      "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
      "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
      "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
      "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
      "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
      "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
      "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
      "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31853, val_acc: 0.96000\n",
      "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
      "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
      "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
      "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31490, val_acc: 0.96000\n",
      "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
      "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
      "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
      "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
      "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
      "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
      "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
      "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
      "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
      "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
      "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
      "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
      "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
      "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
      "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
      "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
      "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
      "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
      "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
      "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
      "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
      "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
      "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
      "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
      "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
      "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
      "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
      "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
      "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
      "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
      "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
      "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
      "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
      "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
      "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
      "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
      "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
      "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
      "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
      "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
      "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
      "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
      "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
      "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
      "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
      "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
      "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
      "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
      "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
      "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
      "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
      "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
      "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
      "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
      "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
      "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
      "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
      "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
      "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
      "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
      "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
      "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
      "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
      "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
      "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
      "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
      "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
      "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
      "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
      "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
      "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
      "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
      "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n",
      "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
      "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n",
      "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
      "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
      "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
      "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
      "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
      "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25921, val_acc: 0.96000\n",
      "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
      "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
      "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
      "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
      "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
      "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
      "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
      "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
      "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
      "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
      "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
      "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
      "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
      "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
      "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
      "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
      "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
      "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
      "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
      "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
      "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
      "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
      "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
      "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
      "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
      "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
      "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
      "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
      "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
      "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
      "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
      "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
      "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
      "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
      "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
      "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
      "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
      "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
      "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
      "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
      "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
      "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
      "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
      "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
      "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
      "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
      "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
      "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
      "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
      "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
      "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
      "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
      "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23287, val_acc: 0.96000\n",
      "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
      "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
      "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
      "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
      "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
      "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
      "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
      "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
      "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
      "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
      "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
      "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
      "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
      "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
      "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
      "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
      "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
      "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
      "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22577, val_acc: 0.96000\n",
      "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
      "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
      "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
      "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
      "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
      "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
      "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
      "Epoch [3140/10000], loss: 0.22358 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
      "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
      "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
      "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
      "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
      "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
      "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
      "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
      "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
      "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
      "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
      "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
      "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
      "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
      "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
      "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
      "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
      "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
      "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
      "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
      "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
      "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
      "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n",
      "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
      "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21483, val_acc: 0.96000\n",
      "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
      "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
      "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21396, val_acc: 0.96000\n",
      "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
      "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n",
      "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
      "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
      "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
      "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
      "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
      "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
      "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
      "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
      "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
      "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
      "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
      "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
      "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
      "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
      "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
      "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
      "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.18622 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18762, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18479, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18395, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.17229 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17589, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16939, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.16094 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15998, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.15215 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.14627 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15314, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15080, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14266, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 訓練フェーズ\n",
    "    \n",
    "    #勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 予測計算\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # 損失計算\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 勾配計算\n",
    "    loss.backward()\n",
    "    \n",
    "    # パラメータ修正\n",
    "    optimizer.step()\n",
    "\n",
    "    #予測ラベル算出\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 損失と精度の計算\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    #予測フェーズ\n",
    "\n",
    "    # 予測計算\n",
    "    outputs_test = net(inputs_test)\n",
    "\n",
    "    # 損失計算\n",
    "    loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "    #予測ラベル算出\n",
    "    predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "    # 損失と精度の計算\n",
    "    val_loss =  loss_test.item()\n",
    "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( epoch % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "6hOWu3ETB8wX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態: 損失: 1.09158 精度: 0.26667\n",
      "最終状態: 損失: 0.13724 精度: 0.96000\n"
     ]
    }
   ],
   "source": [
    "#損失と精度の確認\n",
    "\n",
    "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
    "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "GA3h1wFsB8wX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.1283  -0.0992  -2.4251]\n",
      " [ -4.9799  -0.021   -4.274 ]\n",
      " [ -0.0563  -2.9047 -16.2378]\n",
      " [-11.7813  -3.2099  -0.0412]\n",
      " [ -9.2329  -1.747   -0.1916]]\n",
      "[[0.0059 0.9056 0.0885]\n",
      " [0.0069 0.9792 0.0139]\n",
      " [0.9452 0.0548 0.    ]\n",
      " [0.     0.0404 0.9596]\n",
      " [0.0001 0.1743 0.8256]]\n"
     ]
    }
   ],
   "source": [
    "# パターン1モデルの出力結果\n",
    "w = outputs[:5,:].data\n",
    "print(w.numpy())\n",
    "\n",
    "# 確率値を得たい場合\n",
    "print(torch.exp(w).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiDG6LXeB8wX"
   },
   "source": [
    "### パターン3 モデルクラス側は素のsoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ZK5H4lElB8wX"
   },
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "# 2入力3出力のロジスティック回帰モデル\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_output)\n",
    "        # softmax関数の定義\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "                \n",
    "        # 初期値を全部1にする\n",
    "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
    "        self.l1.weight.data.fill_(1.0)\n",
    "        self.l1.bias.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.softmax(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "pw5Z4sbcB8wX"
   },
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 初期化\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 損失関数： NLLLoss関数\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 最適化関数: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 繰り返し回数\n",
    "num_epochs = 10000\n",
    "\n",
    "# 評価結果記録用\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "3qAnByPtB8wY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
      "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
      "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
      "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
      "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
      "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
      "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
      "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
      "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
      "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
      "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
      "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
      "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
      "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
      "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
      "Epoch [180/10000], loss: 0.62080 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
      "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
      "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
      "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
      "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
      "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
      "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
      "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
      "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
      "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
      "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
      "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
      "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
      "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
      "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
      "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
      "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
      "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
      "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
      "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
      "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
      "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
      "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
      "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
      "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
      "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
      "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
      "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
      "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
      "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
      "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
      "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
      "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
      "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44951, val_acc: 0.90667\n",
      "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
      "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
      "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
      "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
      "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
      "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
      "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
      "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
      "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
      "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
      "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
      "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
      "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
      "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
      "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
      "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
      "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
      "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
      "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
      "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
      "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
      "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
      "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
      "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
      "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
      "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
      "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
      "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
      "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
      "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
      "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
      "Epoch [830/10000], loss: 0.39646 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
      "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
      "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
      "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
      "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
      "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
      "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
      "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
      "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
      "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
      "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
      "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
      "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
      "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
      "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
      "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
      "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
      "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
      "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
      "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35758, val_acc: 0.96000\n",
      "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
      "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35505, val_acc: 0.96000\n",
      "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n",
      "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
      "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
      "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
      "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
      "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
      "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
      "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
      "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
      "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
      "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
      "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
      "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n",
      "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
      "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
      "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
      "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
      "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
      "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
      "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
      "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
      "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
      "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
      "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
      "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
      "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
      "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
      "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
      "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
      "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
      "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
      "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
      "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
      "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31853, val_acc: 0.96000\n",
      "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
      "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
      "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
      "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31489, val_acc: 0.96000\n",
      "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
      "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
      "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
      "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
      "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
      "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
      "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
      "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
      "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
      "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
      "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
      "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
      "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
      "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
      "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
      "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
      "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
      "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
      "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
      "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
      "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
      "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
      "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
      "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
      "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
      "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
      "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
      "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
      "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
      "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
      "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
      "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
      "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
      "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
      "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
      "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
      "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
      "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
      "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
      "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
      "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
      "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
      "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
      "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
      "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
      "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
      "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
      "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
      "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
      "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
      "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
      "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
      "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
      "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
      "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
      "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
      "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
      "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
      "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
      "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
      "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
      "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
      "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
      "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
      "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
      "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
      "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
      "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
      "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
      "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
      "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
      "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
      "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n",
      "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
      "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n",
      "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
      "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
      "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
      "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
      "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
      "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25921, val_acc: 0.96000\n",
      "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
      "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
      "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
      "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
      "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
      "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
      "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
      "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
      "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
      "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
      "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
      "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
      "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
      "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
      "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
      "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
      "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
      "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
      "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
      "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
      "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
      "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
      "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
      "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
      "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
      "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
      "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
      "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
      "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
      "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
      "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
      "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
      "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
      "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
      "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
      "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
      "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
      "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
      "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
      "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
      "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
      "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
      "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
      "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
      "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
      "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
      "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
      "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
      "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
      "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
      "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
      "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
      "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23287, val_acc: 0.96000\n",
      "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
      "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
      "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
      "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
      "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
      "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
      "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
      "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
      "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
      "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
      "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
      "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
      "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
      "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
      "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
      "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
      "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
      "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
      "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22577, val_acc: 0.96000\n",
      "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
      "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
      "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
      "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
      "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
      "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
      "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
      "Epoch [3140/10000], loss: 0.22357 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
      "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
      "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
      "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
      "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
      "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
      "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
      "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
      "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
      "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
      "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
      "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
      "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
      "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
      "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
      "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
      "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
      "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
      "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
      "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
      "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
      "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
      "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n",
      "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
      "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21483, val_acc: 0.96000\n",
      "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
      "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
      "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21396, val_acc: 0.96000\n",
      "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
      "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n",
      "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
      "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
      "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
      "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
      "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
      "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
      "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
      "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
      "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
      "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
      "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
      "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
      "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
      "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
      "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
      "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
      "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.18622 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18762, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18479, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18395, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.17229 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17589, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16939, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.16093 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15997, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.15214 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.14627 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15314, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15080, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14266, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 訓練フェーズ\n",
    "    \n",
    "    #勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 予測計算\n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # ここで対数関数にかける\n",
    "    outputs2 = torch.log(outputs)\n",
    "\n",
    "    # 損失計算\n",
    "    loss = criterion(outputs2, labels)\n",
    "\n",
    "    # 勾配計算\n",
    "    loss.backward()\n",
    "    \n",
    "    # パラメータ修正\n",
    "    optimizer.step()\n",
    "\n",
    "    #予測ラベル算出\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 損失と精度の計算\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    #予測フェーズ\n",
    "\n",
    "    # 予測計算\n",
    "    outputs_test = net(inputs_test)\n",
    "        \n",
    "    # ここで対数関数にかける\n",
    "    outputs2_test = torch.log(outputs_test)\n",
    "\n",
    "    # 損失計算\n",
    "    loss_test = criterion(outputs2_test, labels_test)\n",
    "\n",
    "    #予測ラベル算出\n",
    "    predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "    # 対する損失と精度の計算\n",
    "    val_loss =  loss_test.item()\n",
    "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( epoch % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Nvqi0lCOB8wY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態: 損失: 1.09158 精度: 0.26667\n",
      "最終状態: 損失: 0.13724 精度: 0.96000\n"
     ]
    }
   ],
   "source": [
    "#損失と精度の確認\n",
    "\n",
    "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
    "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_faCAG1B8wY"
   },
   "outputs": [],
   "source": [
    "# パターン2のモデル出力値\n",
    "w = outputs[:5,:].data.numpy()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "HJ2AicieB8wY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1270, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ch07_multi_classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
